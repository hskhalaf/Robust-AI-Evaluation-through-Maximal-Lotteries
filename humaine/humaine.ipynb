{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "863c9bb2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, cvxpy as cp\n",
        "from datasets import load_dataset\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "f8024677",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODELS = ['anthropic/claude-3.7-sonnet', 'anthropic/claude-opus-4', 'anthropic/claude-sonnet-4', 'cohere/command-a', 'cohere/command-r7b-12-2024', 'deepseek/deepseek-r1-0528', 'google/gemini-2.0-flash-001', 'google/gemini-2.5-flash', 'google/gemini-2.5-pro', 'mistralai/mistral-nemo', 'openai/o1', 'openai/o3-mini', 'openai/o4-mini', 'x-ai/grok-3', 'x-ai/grok-4']\n",
        "GROUP_BY = \"ethnic_group\"  # Options: \"political_affiliation\", \"ethnic_group\", or \"metric\"\n",
        "ALPHA = 1.0\n",
        "N_BOOT = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "cca9e039",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_df(group_by=None):\n",
        "    if group_by is None:\n",
        "        group_by = GROUP_BY\n",
        "    ds = load_dataset(\"ProlificAI/humaine-evaluation-dataset\", name=\"feedback_comparisons\", split=\"train\")\n",
        "    df = ds.to_pandas()\n",
        "    df = df[df[\"choice\"] != \"tie\"].copy()\n",
        "    if group_by == \"political_affiliation\":\n",
        "        df[\"group\"] = df[\"political_affiliation\"]\n",
        "    elif group_by == \"ethnic_group\":\n",
        "        df[\"group\"] = df[\"ethnic_group\"]\n",
        "    elif group_by == \"metric\":\n",
        "        df[\"group\"] = df[\"metric\"]\n",
        "        df = df[df[\"group\"] != \"overall winner\"].copy()\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown group_by: {group_by}. Must be 'ethnic_group', 'political_affiliation', or 'metric'\")\n",
        "    df = df[df[\"group\"].notna()].copy()\n",
        "    return df\n",
        "\n",
        "def top_groups(df, group_col=\"group\", k=5):\n",
        "    vc = df[group_col].value_counts(dropna=False)\n",
        "    groups = vc.head(k).index.tolist()\n",
        "    print(groups)\n",
        "    return groups, vc\n",
        "\n",
        "def build_margins(df, groups, models, alpha=0.0, group_col=\"group\"):\n",
        "    m = len(models); K = len(groups)\n",
        "    idx = {name:i for i,name in enumerate(models)}\n",
        "    df = df[df[group_col].isin(groups)].copy()\n",
        "    df = df[df[\"model_a\"].isin(models) & df[\"model_b\"].isin(models)].copy()\n",
        "    counts = df[group_col].value_counts().reindex(groups).fillna(0).astype(int)\n",
        "    tot = int(counts.sum())\n",
        "    if tot == 0: raise ValueError(\"No rows after filtering; check groups/models.\")\n",
        "    w0 = (counts/tot).to_numpy(float)\n",
        "    M_list = []\n",
        "    df = df.copy()\n",
        "    df[\"idx_a\"] = df[\"model_a\"].map(idx)\n",
        "    df[\"idx_b\"] = df[\"model_b\"].map(idx)\n",
        "    df = df.dropna(subset=[\"idx_a\", \"idx_b\"]).copy()\n",
        "    \n",
        "    M_list = []\n",
        "    for grp in groups:\n",
        "        rows = df[df[group_col]==grp]\n",
        "        if len(rows) == 0:\n",
        "            M_list.append(np.zeros((m,m), float))\n",
        "            continue\n",
        "        win = np.zeros((m,m), float)\n",
        "        idx_a = rows[\"idx_a\"].values.astype(int)\n",
        "        idx_b = rows[\"idx_b\"].values.astype(int)\n",
        "        choice = rows[\"choice\"].values\n",
        "        mask_a = (choice == \"A\")\n",
        "        np.add.at(win, (idx_a[mask_a], idx_b[mask_a]), 1.0)\n",
        "        mask_b = (choice == \"B\")\n",
        "        np.add.at(win, (idx_b[mask_b], idx_a[mask_b]), 1.0)\n",
        "        M = np.zeros((m,m), float)\n",
        "        for i in range(m):\n",
        "            for j in range(i+1, m):\n",
        "                tot_ij = win[i,j] + win[j,i]\n",
        "                if tot_ij > 0:\n",
        "                    mij = (win[i,j] - win[j,i]) / (tot_ij + 2.0*alpha)\n",
        "                else:\n",
        "                    mij = 0.0\n",
        "                M[i,j] = mij; M[j,i] = -mij\n",
        "        M_list.append(M)\n",
        "    return M_list, w0, counts, df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2ca6dd21",
      "metadata": {},
      "outputs": [],
      "source": [
        "def solve_drml_tv(M_list, w0, rho, solvers=(\"GUROBI\",\"MOSEK\",\"GLPK\",\"ECOS\")):\n",
        "    K = len(M_list); m = M_list[0].shape[0]\n",
        "    p = cp.Variable(m, nonneg=True); t = cp.Variable()\n",
        "    mu = cp.Variable(m); lam = cp.Variable(m, nonneg=True)\n",
        "    gamma = cp.Variable((m,K))\n",
        "    cons = [cp.sum(p)==1]\n",
        "    for a in range(m):\n",
        "        cons += [t <= mu[a] - 2.0*rho*lam[a] + w0 @ gamma[a,:]]\n",
        "        for k in range(K):\n",
        "            Mk = M_list[k]\n",
        "            cons += [mu[a] + gamma[a,k] <= p @ Mk[:,a],\n",
        "                     gamma[a,k] <= lam[a],\n",
        "                     gamma[a,k] >= -lam[a]]\n",
        "    prob = cp.Problem(cp.Maximize(t), cons)\n",
        "    last = None\n",
        "    for s in solvers:\n",
        "        try:\n",
        "            prob.solve(solver=getattr(cp,s), verbose=False)\n",
        "            if prob.status in (\"optimal\",\"optimal_inaccurate\"): break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "    if prob.status not in (\"optimal\",\"optimal_inaccurate\"):\n",
        "        raise RuntimeError(f\"LP not solved. status={prob.status}, last={last}\")\n",
        "    pval = np.array(p.value).reshape(-1)\n",
        "    pval[pval<0]=0\n",
        "    if pval.sum()>0: pval /= pval.sum()\n",
        "    return pval, float(t.value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "4f420bf9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def per_group_winrate(p, M_list):\n",
        "    M_stack = np.stack(M_list, axis=0)  # (K, m, m)\n",
        "    return per_group_winrate_vectorized(p, M_stack)\n",
        "\n",
        "def per_group_winrate_vectorized(p, M_stack):\n",
        "    pM = np.einsum('i,kij->kj', p, M_stack)\n",
        "    margins = np.min(pM, axis=1)\n",
        "    wr = 0.5 * (1.0 + margins)\n",
        "    return wr\n",
        "\n",
        "def bootstrap_df(df_sub, groups, seed, group_col=\"group\"):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    parts = []\n",
        "    for grp in groups:\n",
        "        part = df_sub[df_sub[group_col]==grp]\n",
        "        n = len(part)\n",
        "        if n == 0: continue\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        parts.append(part.iloc[idx])\n",
        "    return pd.concat(parts, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5709fdae",
      "metadata": {},
      "outputs": [],
      "source": [
        "def bootstrap_margins(df, models, n_boot=200, seed=0, alpha=1.0, group_by=GROUP_BY):\n",
        "    if group_by == \"ethnic_group\":\n",
        "        df[\"group\"] = df[\"ethnic_group\"]\n",
        "        groups, _ = top_groups(df, \"group\", k=4)\n",
        "    elif group_by == \"political_affiliation\":\n",
        "        df[\"group\"] = df[\"political_affiliation\"]\n",
        "        groups, _ = top_groups(df, \"group\", k=4)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown group_by: {group_by}\")\n",
        "\n",
        "    M0, w0, counts, df_sub = build_margins(df, groups, models, alpha=alpha, group_col=\"group\")\n",
        "    print(\"groups:\", groups)\n",
        "    print(\"counts:\", dict(zip(groups, counts.tolist())))\n",
        "    print(\"w0:\", dict(zip(groups, w0.tolist())))\n",
        "    boot_M = []\n",
        "    for b in range(n_boot):\n",
        "        df_b = bootstrap_df(df_sub, groups, seed + 100000*b, group_col=\"group\")\n",
        "        Mb, _, _, _ = build_margins(df_b, groups, models, alpha=alpha, group_col=\"group\")\n",
        "        boot_M.append(Mb)\n",
        "        if (b+1) % max(1, n_boot//10) == 0: print(f\"boot {b+1}/{n_boot}\")\n",
        "    return groups, w0, M0, boot_M\n",
        "\n",
        "def compute_from_bootstrap(groups, w0, boot_M, rhos):\n",
        "    K = len(groups)\n",
        "    boot_wr = {(rho,k): [] for rho in rhos for k in range(K)}\n",
        "    boot_wr_overall = {rho: [] for rho in rhos}\n",
        "    boot_p = {rho: [] for rho in rhos}\n",
        "    boot_v = {rho: [] for rho in rhos}\n",
        "    n_boot = len(boot_M)\n",
        "    w0_arr = np.array(w0, float)\n",
        "    for b, Mb in enumerate(boot_M):\n",
        "        Mb_stack = np.stack(Mb, axis=0)\n",
        "        for rho in rhos:\n",
        "            p, v = solve_drml_tv(Mb, w0, rho)\n",
        "            boot_p[rho].append(p)\n",
        "            boot_v[rho].append(v)  \n",
        "            wr = per_group_winrate_vectorized(p, Mb_stack)\n",
        "            for k in range(K): boot_wr[(rho,k)].append(float(wr[k]))\n",
        "            M_pooled = np.einsum('k,kij->ij', w0_arr, Mb_stack)\n",
        "            overall_margin = float(np.min(p @ M_pooled))\n",
        "            overall_wr = 0.5 * (1 + overall_margin)\n",
        "            boot_wr_overall[rho].append(float(overall_wr))\n",
        "        if (b+1) % max(1, n_boot//10) == 0: print(f\"compute {b+1}/{n_boot}\")\n",
        "    rows = []\n",
        "    for rho in rhos:\n",
        "        for k, lang in enumerate(groups):\n",
        "            arr = np.array(boot_wr[(rho,k)], float)\n",
        "            se = float(arr.std() / np.sqrt(len(arr)))\n",
        "            rows.append({\"rho\": rho, \"group\": lang, \"boot_mean\": float(arr.mean()), \"boot_se\": se})\n",
        "        arr_overall = np.array(boot_wr_overall[rho], float)\n",
        "        se_overall = float(arr_overall.std() / np.sqrt(len(arr_overall)))\n",
        "        rows.append({\"rho\": rho, \"group\": \"overall\", \"boot_mean\": float(arr_overall.mean()), \"boot_se\": se_overall})\n",
        "    ci = pd.DataFrame(rows).sort_values([\"group\",\"rho\"])\n",
        "    return ci, boot_p, boot_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f0782655",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating bootstrap margin matrices...\n",
            "['White', 'Black', 'Asian', 'Mixed']\n",
            "groups: ['White', 'Black', 'Asian', 'Mixed']\n",
            "counts: {'White': 14266, 'Black': 4134, 'Asian': 3359, 'Mixed': 1392}\n",
            "w0: {'White': 0.6162152822772234, 'Black': 0.17856680057016974, 'Asian': 0.14509092479806487, 'Mixed': 0.06012699235454192}\n",
            "boot 20/200\n",
            "boot 40/200\n",
            "boot 60/200\n",
            "boot 80/200\n",
            "boot 100/200\n",
            "boot 120/200\n",
            "boot 140/200\n",
            "boot 160/200\n",
            "boot 180/200\n",
            "boot 200/200\n",
            "Computing results from bootstrap margin matrices...\n",
            "compute 20/200\n",
            "compute 40/200\n",
            "compute 60/200\n",
            "compute 80/200\n",
            "compute 100/200\n",
            "compute 120/200\n",
            "compute 140/200\n",
            "compute 160/200\n",
            "compute 180/200\n",
            "compute 200/200\n"
          ]
        }
      ],
      "source": [
        "df = load_df(group_by=GROUP_BY)\n",
        "rhos = np.linspace(0.0, 1.0, 11)\n",
        "print(\"Generating bootstrap margin matrices...\")\n",
        "groups, w0, M0, boot_M = bootstrap_margins(df, MODELS, n_boot=N_BOOT, seed=1, alpha=ALPHA, group_by=GROUP_BY)\n",
        "print(\"Computing results from bootstrap margin matrices...\")\n",
        "ci, boot_p, boot_v = compute_from_bootstrap(groups, w0, boot_M, rhos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f363d730",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_group_curves(ci, groups, out_pdf=None):\n",
        "    if out_pdf is None:\n",
        "        out_pdf = f\"group_winrate_vs_rho_{GROUP_BY}_ALPHA={ALPHA}.pdf\"\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    sns.set_palette(\"husl\")\n",
        "    \n",
        "    plt.rcParams.update({\n",
        "        \"font.size\": 11,\n",
        "        \"axes.labelsize\": 12,\n",
        "        \"xtick.labelsize\": 10,\n",
        "        \"ytick.labelsize\": 10,\n",
        "        \"legend.fontsize\": 10,\n",
        "        \"pdf.fonttype\": 42,\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"axes.linewidth\": 0.8,\n",
        "        \"grid.linewidth\": 0.5,\n",
        "        \"xtick.major.width\": 0.6,\n",
        "        \"ytick.major.width\": 0.6,\n",
        "    })\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    \n",
        "    default_colors = ['#E74C3C', '#3498DB', '#F39C12', '#27AE60', '#9B59B6', '#1ABC9C', '#E67E22']\n",
        "    colors = {'overall': '#2C3E50'}\n",
        "    for i, grp in enumerate(groups):\n",
        "        if grp not in colors:\n",
        "            colors[grp] = default_colors[i % len(default_colors)]\n",
        "    \n",
        "    desired_order = ['overall'] + list(groups)\n",
        "    \n",
        "    for group in desired_order:\n",
        "        if group == 'overall':\n",
        "            d = ci[ci[\"group\"] == \"overall\"].sort_values(\"rho\")\n",
        "            if len(d) > 0:\n",
        "                x = d[\"rho\"].to_numpy(float)\n",
        "                y = d[\"boot_mean\"].to_numpy(float) * 100.0\n",
        "                se = d[\"boot_se\"].to_numpy(float) * 100.0\n",
        "                ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5, \n",
        "                       label=\"Overall\", linestyle=\"--\", color=colors['overall'], alpha=0.9)\n",
        "                ax.fill_between(x, y - se, y + se, alpha=0.15, color=colors['overall'])\n",
        "        elif group in groups:\n",
        "            d = ci[ci[\"group\"] == group].sort_values(\"rho\")\n",
        "            if len(d) > 0:\n",
        "                x = d[\"rho\"].to_numpy(float)\n",
        "                y = d[\"boot_mean\"].to_numpy(float) * 100.0\n",
        "                se = d[\"boot_se\"].to_numpy(float) * 100.0\n",
        "                ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5, \n",
        "                       label=group, color=colors.get(group, '#95A5A6'), alpha=0.9)\n",
        "                ax.fill_between(x, y - se, y + se, alpha=0.15, color=colors.get(group, '#95A5A6'))\n",
        "    \n",
        "    ax.set_xlabel(r\"$\\rho$\", fontsize=12, labelpad=6)\n",
        "    ax.set_ylabel(\"Win Rate (%)\", fontsize=12, labelpad=6)\n",
        "    \n",
        "    ax.grid(True, alpha=0.25, linestyle='-', linewidth=0.4)\n",
        "    ax.set_axisbelow(True)\n",
        "    \n",
        "    ax.legend(frameon=True, loc='best', framealpha=0.95, facecolor='white', edgecolor='lightgray', borderpad=0.5, labelspacing=0.5, ncol=1, columnspacing=0.8)\n",
        "    \n",
        "    fig.tight_layout()\n",
        "    fig.savefig(out_pdf, bbox_inches=\"tight\", dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(\"saved:\", out_pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "19ef5268",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: group_winrate_vs_rho_ethnic_group_ALPHA=1.0.pdf\n"
          ]
        }
      ],
      "source": [
        "plot_group_curves(ci, groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "99edd17b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def bootstrap_train_test_splits(df, groups, models, train_frac=0.8, n_boot=100, seed=0, group_col=\"group\"):\n",
        "    df_filtered = df[df[group_col].isin(groups)].copy()\n",
        "    df_filtered = df_filtered[df_filtered[\"model_a\"].isin(models) & df_filtered[\"model_b\"].isin(models)].copy()\n",
        "    \n",
        "    splits = []\n",
        "    for b in range(n_boot):\n",
        "        rng = np.random.default_rng(seed + 100000*b)\n",
        "        n_total = len(df_filtered)\n",
        "        boot_idx = rng.integers(0, n_total, size=n_total)\n",
        "        df_boot = df_filtered.iloc[boot_idx].reset_index(drop=True)\n",
        "        \n",
        "        df_train_list = []\n",
        "        df_test_list = []\n",
        "        for grp in groups:\n",
        "            grp_df = df_boot[df_boot[group_col] == grp]\n",
        "            n = len(grp_df)\n",
        "            if n == 0:\n",
        "                continue\n",
        "            n_train = int(train_frac * n)\n",
        "            idx = np.arange(n)\n",
        "            rng.shuffle(idx)\n",
        "            train_idx = idx[:n_train]\n",
        "            test_idx = idx[n_train:]\n",
        "            df_train_list.append(grp_df.iloc[train_idx])\n",
        "            df_test_list.append(grp_df.iloc[test_idx])\n",
        "        if len(df_train_list) == 0:\n",
        "            continue\n",
        "        df_train = pd.concat(df_train_list, ignore_index=True)\n",
        "        df_test = pd.concat(df_test_list, ignore_index=True)\n",
        "        splits.append((df_train, df_test))\n",
        "        if (b+1) % max(1, n_boot//10) == 0: print(f\"boot {b+1}/{n_boot}\")\n",
        "    return splits\n",
        "\n",
        "def compute_generalization(splits, groups, models, rhos, alpha=1.0, group_col=\"group\"):\n",
        "    K = len(groups)\n",
        "    boot_wr_train = {(rho, grp): [] for rho in rhos for grp in groups + [\"overall\"]}\n",
        "    boot_wr_test = {(rho, grp): [] for rho in rhos for grp in groups + [\"overall\"]}\n",
        "    \n",
        "    for df_train, df_test in splits:\n",
        "        M_train, w0_train, _, _ = build_margins(df_train, groups, models, alpha=alpha, group_col=group_col)\n",
        "        M_test, w0_test, _, _ = build_margins(df_test, groups, models, alpha=alpha, group_col=group_col)\n",
        "        \n",
        "        M_train_stack = np.stack(M_train, axis=0)\n",
        "        w0_train_arr = np.array(w0_train, float)\n",
        "        M_test_stack = np.stack(M_test, axis=0)\n",
        "        w0_test_arr = np.array(w0_test, float)\n",
        "        \n",
        "        for rho in rhos:\n",
        "            p_rho, _ = solve_drml_tv(M_train, w0_train, rho)\n",
        "            \n",
        "            wr_train = per_group_winrate_vectorized(p_rho, M_train_stack)\n",
        "            for k, grp in enumerate(groups): \n",
        "                boot_wr_train[(rho, grp)].append(float(wr_train[k]))\n",
        "            \n",
        "            M_pooled_train = np.einsum('k,kij->ij', w0_train_arr, M_train_stack)\n",
        "            v_train_overall = float(np.min(p_rho @ M_pooled_train))\n",
        "            wr_train_overall = 0.5 * (1 + v_train_overall)\n",
        "            boot_wr_train[(rho, \"overall\")].append(float(wr_train_overall))\n",
        "            \n",
        "            wr_test = per_group_winrate_vectorized(p_rho, M_test_stack)\n",
        "            for k, grp in enumerate(groups): \n",
        "                boot_wr_test[(rho, grp)].append(float(wr_test[k]))\n",
        "            \n",
        "            M_pooled_test = np.einsum('k,kij->ij', w0_test_arr, M_test_stack)\n",
        "            v_test_overall = float(np.min(p_rho @ M_pooled_test))\n",
        "            wr_test_overall = 0.5 * (1 + v_test_overall)\n",
        "            boot_wr_test[(rho, \"overall\")].append(float(wr_test_overall))\n",
        "    \n",
        "    gap_rows = []\n",
        "    for rho in rhos:\n",
        "        for grp in groups + [\"overall\"]:\n",
        "            arr_train = np.array(boot_wr_train[(rho, grp)], float)\n",
        "            arr_test = np.array(boot_wr_test[(rho, grp)], float)\n",
        "            if len(arr_train) > 0 and len(arr_test) > 0:\n",
        "                train_mean = float(arr_train.mean())\n",
        "                test_mean = float(arr_test.mean())\n",
        "                gap = train_mean - test_mean\n",
        "                se_train = float(arr_train.std() / np.sqrt(len(arr_train)))\n",
        "                se_test = float(arr_test.std() / np.sqrt(len(arr_test)))\n",
        "                se_gap = float(np.sqrt(arr_train.var() + arr_test.var()) / np.sqrt(len(arr_train)))\n",
        "                gap_rows.append({\n",
        "                    \"rho\": rho,\n",
        "                    \"group\": grp,\n",
        "                    \"wr_train_mean\": train_mean,\n",
        "                    \"wr_test_mean\": test_mean,\n",
        "                    \"wr_gap_mean\": gap,\n",
        "                    \"wr_train_se\": se_train,\n",
        "                    \"wr_test_se\": se_test,\n",
        "                    \"wr_gap_se\": se_gap\n",
        "                })\n",
        "    gap_df = pd.DataFrame(gap_rows)\n",
        "    return gap_df, boot_wr_train, boot_wr_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "df2b138c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating bootstrap train/test splits...\n",
            "boot 20/200\n",
            "boot 40/200\n",
            "boot 60/200\n",
            "boot 80/200\n",
            "boot 100/200\n",
            "boot 120/200\n",
            "boot 140/200\n",
            "boot 160/200\n",
            "boot 180/200\n",
            "boot 200/200\n",
            "Computing generalization gaps from splits...\n"
          ]
        }
      ],
      "source": [
        "print(\"Generating bootstrap train/test splits...\")\n",
        "splits = bootstrap_train_test_splits(df, groups, MODELS, train_frac=0.8, n_boot=N_BOOT, seed=42, group_col=\"group\")\n",
        "print(\"Computing generalization gaps from splits...\")\n",
        "gap_df, _, _ = compute_generalization(splits, groups, MODELS, rhos, alpha=ALPHA, group_col=\"group\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "fc44e342",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_winrate_heldout(gap_df, groups, out_pdf=None):\n",
        "    if out_pdf is None:\n",
        "        out_pdf = f\"winrate_heldout_{GROUP_BY}_ALPHA={ALPHA}.pdf\"\n",
        "    lang_names = {'en': 'English', 'pl': 'Polish', 'ru': 'Russian', 'zh': 'Chinese', 'overall': 'Overall'}\n",
        "    \n",
        "    sns.set_style(\"whitegrid\")\n",
        "    sns.set_palette(\"husl\")\n",
        "    \n",
        "    plt.rcParams.update({\n",
        "        \"font.size\": 11,\n",
        "        \"axes.labelsize\": 12,\n",
        "        \"xtick.labelsize\": 10,\n",
        "        \"ytick.labelsize\": 10,\n",
        "        \"legend.fontsize\": 10,\n",
        "        \"pdf.fonttype\": 42,\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"axes.linewidth\": 0.8,\n",
        "        \"grid.linewidth\": 0.5,\n",
        "        \"xtick.major.width\": 0.6,\n",
        "        \"ytick.major.width\": 0.6,\n",
        "    })\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    \n",
        "    default_colors = ['#E74C3C', '#3498DB', '#F39C12', '#27AE60', '#9B59B6', '#1ABC9C', '#E67E22']\n",
        "    colors = {'overall': '#2C3E50'}\n",
        "    for i, grp in enumerate(groups):\n",
        "        if grp not in colors:\n",
        "            colors[grp] = default_colors[i % len(default_colors)]\n",
        "    \n",
        "    desired_order = ['overall'] + list(groups)\n",
        "    \n",
        "    for group in desired_order:\n",
        "        if group == 'overall':\n",
        "            d = gap_df[gap_df[\"group\"] == \"overall\"].sort_values(\"rho\")\n",
        "            if len(d) > 0:\n",
        "                x = d[\"rho\"].to_numpy(float)\n",
        "                y = d[\"wr_test_mean\"].to_numpy(float) * 100.0\n",
        "                se = d[\"wr_test_se\"].to_numpy(float) * 100.0\n",
        "                ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5,\n",
        "                       label=\"Overall\", linestyle=\"--\", color=colors['overall'], alpha=0.9)\n",
        "                ax.fill_between(x, y - se, y + se, alpha=0.15, color=colors['overall'])\n",
        "        elif group in groups:\n",
        "            d = gap_df[gap_df[\"group\"] == group].sort_values(\"rho\")\n",
        "            if len(d) > 0:\n",
        "                x = d[\"rho\"].to_numpy(float)\n",
        "                y = d[\"wr_test_mean\"].to_numpy(float) * 100.0\n",
        "                se = d[\"wr_test_se\"].to_numpy(float) * 100.0\n",
        "                group_label = lang_names.get(group, group)\n",
        "                ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5,\n",
        "                       label=group_label, color=colors.get(group, '#95A5A6'), alpha=0.9)\n",
        "                ax.fill_between(x, y - se, y + se, alpha=0.15, color=colors.get(group, '#95A5A6'))\n",
        "    \n",
        "    ax.set_xlabel(r\"$\\rho$\", fontsize=12, labelpad=6)\n",
        "    ax.set_ylabel(\"\", fontsize=12, labelpad=6)\n",
        "    \n",
        "    ax.grid(True, alpha=0.25, linestyle='-', linewidth=0.4)\n",
        "    ax.set_axisbelow(True)\n",
        "    if GROUP_BY == \"political_affiliation\":\n",
        "        ax.legend(frameon=True, loc=(0.7, 0.43), framealpha=0.95, facecolor='white', edgecolor='lightgray', borderpad=0.8, labelspacing=0.6, ncol=1, columnspacing=0.8)\n",
        "    else:\n",
        "        ax.legend(frameon=True, loc='best', framealpha=0.95, facecolor='white', edgecolor='lightgray', borderpad=0.8, labelspacing=0.6, ncol=1, columnspacing=0.8)\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(out_pdf, bbox_inches=\"tight\", dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(\"saved:\", out_pdf)\n",
        "\n",
        "def print_winrate_heldout(gap_df, groups):\n",
        "    lang_names = {'en': 'English', 'pl': 'Polish', 'ru': 'Russian', 'zh': 'Chinese', 'overall': 'Overall'}\n",
        "    gap_df = gap_df.copy()\n",
        "    gap_df[\"formatted\"] = gap_df.apply(\n",
        "        lambda row: f\"{row['wr_test_mean']:.4f} ± {row['wr_test_se']:.4f}\", axis=1\n",
        "    )\n",
        "    table = gap_df.pivot(index=\"group\", columns=\"rho\", values=\"formatted\")\n",
        "    all_groups = groups + [\"overall\"]\n",
        "    table = table.reindex(all_groups)\n",
        "    table.index = [lang_names.get(grp, grp) for grp in table.index]\n",
        "    display(table)\n",
        "    return table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "49b1605c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Winrate on held-out data:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rho</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>White</th>\n",
              "      <td>0.4514 ± 0.0033</td>\n",
              "      <td>0.4544 ± 0.0025</td>\n",
              "      <td>0.4531 ± 0.0022</td>\n",
              "      <td>0.4496 ± 0.0021</td>\n",
              "      <td>0.4430 ± 0.0022</td>\n",
              "      <td>0.4364 ± 0.0022</td>\n",
              "      <td>0.4282 ± 0.0023</td>\n",
              "      <td>0.4195 ± 0.0023</td>\n",
              "      <td>0.4146 ± 0.0024</td>\n",
              "      <td>0.4134 ± 0.0024</td>\n",
              "      <td>0.4130 ± 0.0024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Black</th>\n",
              "      <td>0.2909 ± 0.0061</td>\n",
              "      <td>0.3280 ± 0.0053</td>\n",
              "      <td>0.3528 ± 0.0047</td>\n",
              "      <td>0.3638 ± 0.0044</td>\n",
              "      <td>0.3704 ± 0.0041</td>\n",
              "      <td>0.3789 ± 0.0039</td>\n",
              "      <td>0.3854 ± 0.0036</td>\n",
              "      <td>0.3896 ± 0.0034</td>\n",
              "      <td>0.3934 ± 0.0031</td>\n",
              "      <td>0.3951 ± 0.0031</td>\n",
              "      <td>0.3955 ± 0.0031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Asian</th>\n",
              "      <td>0.3636 ± 0.0056</td>\n",
              "      <td>0.3957 ± 0.0042</td>\n",
              "      <td>0.4099 ± 0.0034</td>\n",
              "      <td>0.4125 ± 0.0032</td>\n",
              "      <td>0.4096 ± 0.0030</td>\n",
              "      <td>0.4081 ± 0.0031</td>\n",
              "      <td>0.4039 ± 0.0030</td>\n",
              "      <td>0.4004 ± 0.0030</td>\n",
              "      <td>0.3969 ± 0.0030</td>\n",
              "      <td>0.3958 ± 0.0030</td>\n",
              "      <td>0.3956 ± 0.0030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mixed</th>\n",
              "      <td>0.3097 ± 0.0055</td>\n",
              "      <td>0.3304 ± 0.0043</td>\n",
              "      <td>0.3451 ± 0.0038</td>\n",
              "      <td>0.3532 ± 0.0037</td>\n",
              "      <td>0.3600 ± 0.0036</td>\n",
              "      <td>0.3669 ± 0.0034</td>\n",
              "      <td>0.3730 ± 0.0034</td>\n",
              "      <td>0.3780 ± 0.0032</td>\n",
              "      <td>0.3810 ± 0.0032</td>\n",
              "      <td>0.3828 ± 0.0031</td>\n",
              "      <td>0.3830 ± 0.0031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Overall</th>\n",
              "      <td>0.4669 ± 0.0025</td>\n",
              "      <td>0.4705 ± 0.0018</td>\n",
              "      <td>0.4698 ± 0.0014</td>\n",
              "      <td>0.4664 ± 0.0014</td>\n",
              "      <td>0.4610 ± 0.0015</td>\n",
              "      <td>0.4553 ± 0.0016</td>\n",
              "      <td>0.4492 ± 0.0016</td>\n",
              "      <td>0.4432 ± 0.0018</td>\n",
              "      <td>0.4391 ± 0.0018</td>\n",
              "      <td>0.4378 ± 0.0018</td>\n",
              "      <td>0.4373 ± 0.0018</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "rho                  0.0              0.1              0.2              0.3  \\\n",
              "White    0.4514 ± 0.0033  0.4544 ± 0.0025  0.4531 ± 0.0022  0.4496 ± 0.0021   \n",
              "Black    0.2909 ± 0.0061  0.3280 ± 0.0053  0.3528 ± 0.0047  0.3638 ± 0.0044   \n",
              "Asian    0.3636 ± 0.0056  0.3957 ± 0.0042  0.4099 ± 0.0034  0.4125 ± 0.0032   \n",
              "Mixed    0.3097 ± 0.0055  0.3304 ± 0.0043  0.3451 ± 0.0038  0.3532 ± 0.0037   \n",
              "Overall  0.4669 ± 0.0025  0.4705 ± 0.0018  0.4698 ± 0.0014  0.4664 ± 0.0014   \n",
              "\n",
              "rho                  0.4              0.5              0.6              0.7  \\\n",
              "White    0.4430 ± 0.0022  0.4364 ± 0.0022  0.4282 ± 0.0023  0.4195 ± 0.0023   \n",
              "Black    0.3704 ± 0.0041  0.3789 ± 0.0039  0.3854 ± 0.0036  0.3896 ± 0.0034   \n",
              "Asian    0.4096 ± 0.0030  0.4081 ± 0.0031  0.4039 ± 0.0030  0.4004 ± 0.0030   \n",
              "Mixed    0.3600 ± 0.0036  0.3669 ± 0.0034  0.3730 ± 0.0034  0.3780 ± 0.0032   \n",
              "Overall  0.4610 ± 0.0015  0.4553 ± 0.0016  0.4492 ± 0.0016  0.4432 ± 0.0018   \n",
              "\n",
              "rho                  0.8              0.9              1.0  \n",
              "White    0.4146 ± 0.0024  0.4134 ± 0.0024  0.4130 ± 0.0024  \n",
              "Black    0.3934 ± 0.0031  0.3951 ± 0.0031  0.3955 ± 0.0031  \n",
              "Asian    0.3969 ± 0.0030  0.3958 ± 0.0030  0.3956 ± 0.0030  \n",
              "Mixed    0.3810 ± 0.0032  0.3828 ± 0.0031  0.3830 ± 0.0031  \n",
              "Overall  0.4391 ± 0.0018  0.4378 ± 0.0018  0.4373 ± 0.0018  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: winrate_heldout_ethnic_group_ALPHA=1.0.pdf\n"
          ]
        }
      ],
      "source": [
        "print(\"Winrate on held-out data:\")\n",
        "print_winrate_heldout(gap_df, groups)\n",
        "plot_winrate_heldout(gap_df, groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "d46832f6",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: generalization_GROUP=ethnic_group_ALPHA=1.0.pdf\n"
          ]
        }
      ],
      "source": [
        "def plot_generalization(gap_df, out_pdf=f\"generalization_GROUP={GROUP_BY}_ALPHA={ALPHA}.pdf\"):\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    \n",
        "    plt.rcParams.update({\n",
        "        \"font.size\": 11,\n",
        "        \"axes.labelsize\": 12,\n",
        "        \"xtick.labelsize\": 10,\n",
        "        \"ytick.labelsize\": 10,\n",
        "        \"legend.fontsize\": 10,\n",
        "        \"pdf.fonttype\": 42,\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"axes.linewidth\": 0.8,\n",
        "        \"grid.linewidth\": 0.5,\n",
        "        \"xtick.major.width\": 0.6,\n",
        "        \"ytick.major.width\": 0.6,\n",
        "    })\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    \n",
        "    # Plot overall generalization gap\n",
        "    d = gap_df[gap_df[\"group\"] == \"overall\"].sort_values(\"rho\")\n",
        "    if len(d) > 0:\n",
        "        x = d[\"rho\"].to_numpy(float)\n",
        "        y = d[\"wr_gap_mean\"].to_numpy(float) * 100.0\n",
        "        se = d[\"wr_gap_se\"].to_numpy(float) * 100.0\n",
        "        ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5,\n",
        "               label=\"Overall\", linestyle=\"--\", color='#2C3E50', alpha=0.9)\n",
        "        ax.fill_between(x, y - se, y + se, alpha=0.15, color='#2C3E50')\n",
        "    \n",
        "    ax.set_xlabel(r\"$\\rho$\", fontsize=12, labelpad=6)\n",
        "    ax.set_ylabel(\"Win rate generalization gap (%)\", fontsize=12, labelpad=6)\n",
        "    \n",
        "    ax.grid(True, alpha=0.25, linestyle='-', linewidth=0.4)\n",
        "    ax.set_axisbelow(True)\n",
        "    \n",
        "    ax.axhline(y=0, color='gray', linestyle='--', linewidth=0.8, alpha=0.5)\n",
        "    \n",
        "    fig.tight_layout()\n",
        "    fig.savefig(out_pdf, bbox_inches=\"tight\", dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(\"saved:\", out_pdf)\n",
        "\n",
        "plot_generalization(gap_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "76d21a02",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(shown if mean> 2.0% for some rho)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rho</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>google/gemini-2.5-pro</th>\n",
              "      <td>71.78 ± 2.25</td>\n",
              "      <td>63.55 ± 1.37</td>\n",
              "      <td>58.03 ± 0.90</td>\n",
              "      <td>52.60 ± 0.79</td>\n",
              "      <td>47.43 ± 0.77</td>\n",
              "      <td>42.07 ± 0.79</td>\n",
              "      <td>38.05 ± 0.79</td>\n",
              "      <td>34.10 ± 0.78</td>\n",
              "      <td>31.93 ± 0.77</td>\n",
              "      <td>31.05 ± 0.73</td>\n",
              "      <td>30.76 ± 0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x-ai/grok-4</th>\n",
              "      <td>16.41 ± 1.53</td>\n",
              "      <td>12.89 ± 1.03</td>\n",
              "      <td>10.17 ± 0.67</td>\n",
              "      <td>10.33 ± 0.66</td>\n",
              "      <td>10.33 ± 0.64</td>\n",
              "      <td>11.11 ± 0.68</td>\n",
              "      <td>10.77 ± 0.66</td>\n",
              "      <td>10.48 ± 0.67</td>\n",
              "      <td>10.59 ± 0.68</td>\n",
              "      <td>10.62 ± 0.69</td>\n",
              "      <td>10.79 ± 0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x-ai/grok-3</th>\n",
              "      <td>11.33 ± 1.54</td>\n",
              "      <td>22.74 ± 1.05</td>\n",
              "      <td>29.80 ± 0.73</td>\n",
              "      <td>31.05 ± 0.68</td>\n",
              "      <td>31.61 ± 0.69</td>\n",
              "      <td>31.92 ± 0.73</td>\n",
              "      <td>31.48 ± 0.77</td>\n",
              "      <td>31.43 ± 0.76</td>\n",
              "      <td>30.79 ± 0.76</td>\n",
              "      <td>30.31 ± 0.71</td>\n",
              "      <td>30.07 ± 0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anthropic/claude-opus-4</th>\n",
              "      <td>0.38 ± 0.17</td>\n",
              "      <td>0.71 ± 0.21</td>\n",
              "      <td>0.85 ± 0.26</td>\n",
              "      <td>2.78 ± 0.47</td>\n",
              "      <td>5.52 ± 0.72</td>\n",
              "      <td>7.71 ± 0.80</td>\n",
              "      <td>10.03 ± 0.85</td>\n",
              "      <td>12.17 ± 0.86</td>\n",
              "      <td>13.67 ± 0.86</td>\n",
              "      <td>14.66 ± 0.87</td>\n",
              "      <td>14.90 ± 0.87</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>google/gemini-2.5-flash</th>\n",
              "      <td>0.08 ± 0.05</td>\n",
              "      <td>0.07 ± 0.06</td>\n",
              "      <td>0.91 ± 0.21</td>\n",
              "      <td>2.17 ± 0.31</td>\n",
              "      <td>2.51 ± 0.37</td>\n",
              "      <td>2.22 ± 0.34</td>\n",
              "      <td>2.08 ± 0.30</td>\n",
              "      <td>2.05 ± 0.31</td>\n",
              "      <td>2.04 ± 0.32</td>\n",
              "      <td>2.15 ± 0.33</td>\n",
              "      <td>2.24 ± 0.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek/deepseek-r1-0528</th>\n",
              "      <td>0.03 ± 0.03</td>\n",
              "      <td>0.05 ± 0.03</td>\n",
              "      <td>0.23 ± 0.08</td>\n",
              "      <td>0.95 ± 0.18</td>\n",
              "      <td>2.14 ± 0.25</td>\n",
              "      <td>3.88 ± 0.35</td>\n",
              "      <td>5.96 ± 0.46</td>\n",
              "      <td>7.01 ± 0.51</td>\n",
              "      <td>7.74 ± 0.56</td>\n",
              "      <td>7.54 ± 0.57</td>\n",
              "      <td>7.52 ± 0.58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>anthropic/claude-sonnet-4</th>\n",
              "      <td>0.00 ± 0.00</td>\n",
              "      <td>0.00 ± 0.00</td>\n",
              "      <td>0.01 ± 0.01</td>\n",
              "      <td>0.12 ± 0.05</td>\n",
              "      <td>0.40 ± 0.12</td>\n",
              "      <td>0.84 ± 0.19</td>\n",
              "      <td>1.25 ± 0.25</td>\n",
              "      <td>1.93 ± 0.35</td>\n",
              "      <td>2.07 ± 0.35</td>\n",
              "      <td>2.34 ± 0.38</td>\n",
              "      <td>2.38 ± 0.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "rho                                 0.0           0.1           0.2  \\\n",
              "model                                                                 \n",
              "google/gemini-2.5-pro      71.78 ± 2.25  63.55 ± 1.37  58.03 ± 0.90   \n",
              "x-ai/grok-4                16.41 ± 1.53  12.89 ± 1.03  10.17 ± 0.67   \n",
              "x-ai/grok-3                11.33 ± 1.54  22.74 ± 1.05  29.80 ± 0.73   \n",
              "anthropic/claude-opus-4     0.38 ± 0.17   0.71 ± 0.21   0.85 ± 0.26   \n",
              "google/gemini-2.5-flash     0.08 ± 0.05   0.07 ± 0.06   0.91 ± 0.21   \n",
              "deepseek/deepseek-r1-0528   0.03 ± 0.03   0.05 ± 0.03   0.23 ± 0.08   \n",
              "anthropic/claude-sonnet-4   0.00 ± 0.00   0.00 ± 0.00   0.01 ± 0.01   \n",
              "\n",
              "rho                                 0.3           0.4           0.5  \\\n",
              "model                                                                 \n",
              "google/gemini-2.5-pro      52.60 ± 0.79  47.43 ± 0.77  42.07 ± 0.79   \n",
              "x-ai/grok-4                10.33 ± 0.66  10.33 ± 0.64  11.11 ± 0.68   \n",
              "x-ai/grok-3                31.05 ± 0.68  31.61 ± 0.69  31.92 ± 0.73   \n",
              "anthropic/claude-opus-4     2.78 ± 0.47   5.52 ± 0.72   7.71 ± 0.80   \n",
              "google/gemini-2.5-flash     2.17 ± 0.31   2.51 ± 0.37   2.22 ± 0.34   \n",
              "deepseek/deepseek-r1-0528   0.95 ± 0.18   2.14 ± 0.25   3.88 ± 0.35   \n",
              "anthropic/claude-sonnet-4   0.12 ± 0.05   0.40 ± 0.12   0.84 ± 0.19   \n",
              "\n",
              "rho                                 0.6           0.7           0.8  \\\n",
              "model                                                                 \n",
              "google/gemini-2.5-pro      38.05 ± 0.79  34.10 ± 0.78  31.93 ± 0.77   \n",
              "x-ai/grok-4                10.77 ± 0.66  10.48 ± 0.67  10.59 ± 0.68   \n",
              "x-ai/grok-3                31.48 ± 0.77  31.43 ± 0.76  30.79 ± 0.76   \n",
              "anthropic/claude-opus-4    10.03 ± 0.85  12.17 ± 0.86  13.67 ± 0.86   \n",
              "google/gemini-2.5-flash     2.08 ± 0.30   2.05 ± 0.31   2.04 ± 0.32   \n",
              "deepseek/deepseek-r1-0528   5.96 ± 0.46   7.01 ± 0.51   7.74 ± 0.56   \n",
              "anthropic/claude-sonnet-4   1.25 ± 0.25   1.93 ± 0.35   2.07 ± 0.35   \n",
              "\n",
              "rho                                 0.9           1.0  \n",
              "model                                                  \n",
              "google/gemini-2.5-pro      31.05 ± 0.73  30.76 ± 0.72  \n",
              "x-ai/grok-4                10.62 ± 0.69  10.79 ± 0.70  \n",
              "x-ai/grok-3                30.31 ± 0.71  30.07 ± 0.69  \n",
              "anthropic/claude-opus-4    14.66 ± 0.87  14.90 ± 0.87  \n",
              "google/gemini-2.5-flash     2.15 ± 0.33   2.24 ± 0.33  \n",
              "deepseek/deepseek-r1-0528   7.54 ± 0.57   7.52 ± 0.58  \n",
              "anthropic/claude-sonnet-4   2.34 ± 0.38   2.38 ± 0.38  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def print_boot_p(boot_p, models, rhos, thresh=0.02):\n",
        "    rows = []\n",
        "    for rho in rhos:\n",
        "        P = np.vstack(boot_p[rho])\n",
        "        mean = P.mean(axis=0)\n",
        "        se = P.std(axis=0) / np.sqrt(P.shape[0])\n",
        "        for i, name in enumerate(models):\n",
        "            rows.append({\"rho\": rho, \"model\": name, \"mean\": mean[i], \"se\": se[i]})\n",
        "    wdf = pd.DataFrame(rows)\n",
        "    keep = wdf.groupby(\"model\")[\"mean\"].max()\n",
        "    keep = keep[keep > thresh].index\n",
        "    wdf = wdf[wdf[\"model\"].isin(keep)].copy()\n",
        "    wdf[\"mean%\"] = (100*wdf[\"mean\"]).round(2)\n",
        "    wdf[\"se%\"] = (100*wdf[\"se\"]).round(2)\n",
        "    \n",
        "    wdf[\"formatted\"] = wdf.apply(lambda row: f\"{row['mean%']:.2f} ± {row['se%']:.2f}\", axis=1)\n",
        "    \n",
        "    table = wdf.pivot(index=\"model\", columns=\"rho\", values=\"formatted\")\n",
        "    \n",
        "    rho0_means = wdf[wdf[\"rho\"] == rhos[0]].set_index(\"model\")[\"mean\"].sort_values(ascending=False)\n",
        "    table = table.reindex(rho0_means.index)\n",
        "    \n",
        "    print(f\"(shown if mean> {100*thresh:.1f}% for some rho)\")\n",
        "    display(table)\n",
        "    return wdf\n",
        "\n",
        "wdf = print_boot_p(boot_p, MODELS, rhos, thresh=0.02)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "7a53c187",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_model_performance_grid(wdf, model_shortcuts=None, model_colors=None, out_pdf=None):\n",
        "    if out_pdf is None:\n",
        "        out_pdf = f\"model_performance_grid_{GROUP_BY}_ALPHA={ALPHA}.pdf\"\n",
        "    \n",
        "    sns.set_style(\"white\")\n",
        "    \n",
        "    plt.rcParams.update({\n",
        "        \"font.size\": 10,\n",
        "        \"axes.labelsize\": 11,\n",
        "        \"xtick.labelsize\": 9,\n",
        "        \"ytick.labelsize\": 10,\n",
        "        \"legend.fontsize\": 10,\n",
        "        \"pdf.fonttype\": 42,\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"axes.linewidth\": 0.8,\n",
        "        \"grid.linewidth\": 0.4,\n",
        "        \"xtick.major.width\": 0.6,\n",
        "        \"ytick.major.width\": 0,\n",
        "    })\n",
        "    \n",
        "    default_shortcuts = {\n",
        "        'x-ai/grok-3': 'Grok 3',\n",
        "        'google/gemini-2.5-pro': 'Gemini 2.5 Pro',\n",
        "        'x-ai/grok-4': 'Grok 4',\n",
        "        'google/gemini-2.5-flash': 'Gemini 2.5 Flash',\n",
        "        'deepseek/deepseek-r1-0528': 'DeepSeek R1',\n",
        "        'anthropic/claude-opus-4': 'Claude Opus 4',\n",
        "        'anthropic/claude-sonnet-4': 'Claude Sonnet 4',\n",
        "    }\n",
        "    \n",
        "    default_colors = {\n",
        "        'x-ai/grok-3': '#E74C3C',\n",
        "        'google/gemini-2.5-pro': '#3498DB',\n",
        "        'x-ai/grok-4': '#F39C12',\n",
        "        'google/gemini-2.5-flash': '#27AE60',\n",
        "        'deepseek/deepseek-r1-0528': '#9B59B6',\n",
        "        'anthropic/claude-opus-4': '#1ABC9C',\n",
        "        'anthropic/claude-sonnet-4': '#E67E22',\n",
        "    }\n",
        "    \n",
        "    model_names = model_shortcuts if model_shortcuts is not None else default_shortcuts\n",
        "    colors = model_colors if model_colors is not None else default_colors\n",
        "    \n",
        "    unique_rhos = sorted(wdf[\"rho\"].unique())\n",
        "    rhos_to_plot = [0.0, 0.4, 0.7, 1.0]\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 4, figsize=(18, 5))\n",
        "    \n",
        "    models_ordered = wdf[np.isclose(wdf[\"rho\"], 0.0)].sort_values(\"mean\", ascending=True)[\"model\"].values\n",
        "    \n",
        "    for idx, rho in enumerate(rhos_to_plot):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        data = wdf[np.isclose(wdf[\"rho\"], rho)].copy()\n",
        "        data = data.set_index(\"model\").reindex(models_ordered).reset_index()\n",
        "        data = data.dropna()\n",
        "        \n",
        "        bar_spacing = 0.65\n",
        "        y_pos = np.arange(len(data)) * bar_spacing\n",
        "        bar_colors = [colors.get(m, '#95A5A6') for m in data[\"model\"]]\n",
        "        \n",
        "        ax.barh(y_pos, data[\"mean%\"], xerr=data[\"se%\"], \n",
        "               color=bar_colors,\n",
        "               error_kw={'elinewidth': 1.2, 'capsize': 2.5, 'alpha': 0.7},\n",
        "               height=0.5 * bar_spacing, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
        "        \n",
        "        ax.set_xlim(0, 75)\n",
        "        ax.set_xticks([0, 20, 40, 60, 80])\n",
        "        \n",
        "        ax.set_axisbelow(True)\n",
        "        ax.grid(True, axis='x', alpha=0.25, linestyle='-', linewidth=0.5, color='gray')\n",
        "        ax.grid(True, axis='y', alpha=0.15, linestyle='-', linewidth=0.3, color='gray')\n",
        "        \n",
        "\n",
        "        ax.set_yticks(y_pos)\n",
        "        if idx == 0:\n",
        "            clean_names = [model_names.get(m, m) for m in data[\"model\"]]\n",
        "            ax.set_yticklabels(clean_names, fontsize=12)\n",
        "        else:\n",
        "            ax.set_yticklabels([]) \n",
        "            \n",
        "        ax.set_xlabel(\"Probability (%)\", fontsize=14, labelpad=4)\n",
        "        ax.set_xticklabels(['0', '20', '40', '60', '80'], fontsize=14)\n",
        "        \n",
        "        rho_label = f'ρ = {rho:.1f}'\n",
        "        ax.text(0.95, 0.1, rho_label, transform=ax.transAxes,\n",
        "               fontsize=16, fontweight='bold', ha='right', va='bottom',\n",
        "               bbox=dict(boxstyle='round,pad=0.4', facecolor='white', \n",
        "                        edgecolor='lightgray', alpha=0.8, linewidth=0.5))\n",
        "        \n",
        "        ax.spines['left'].set_linewidth(0.8)\n",
        "        ax.spines['bottom'].set_linewidth(0.8)\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['right'].set_visible(False)\n",
        "    \n",
        "    fig.tight_layout(pad=1.2)\n",
        "    fig.savefig(out_pdf, bbox_inches=\"tight\", dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(f\"saved: {out_pdf}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "3684a0c1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: model_performance_grid_ethnic_group_ALPHA=1.0.pdf\n"
          ]
        }
      ],
      "source": [
        "plot_model_performance_grid(wdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "fefc4257",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================================================================================\n",
            "TOP 10 MODEL PAIRS WITH MOST INCONSISTENT RANKINGS ACROSS GROUPS\n",
            "================================================================================\n",
            "\n",
            "Rank 1: Grok 3 vs Gemini 2.5 Flash\n",
            "  Inconsistency score (weighted): 0.475\n",
            "  Total comparisons across groups: 314\n",
            "\n",
            "  Groups where 'Grok 3' beats 'Gemini 2.5 Flash' (2):\n",
            "    - Black: 43 comparisons\n",
            "    - Asian: 79 comparisons\n",
            "\n",
            "  Groups where 'Gemini 2.5 Flash' beats 'Grok 3' (2):\n",
            "    - White: 179 comparisons\n",
            "    - Mixed: 13 comparisons\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 2: o1 vs Command A\n",
            "  Inconsistency score (weighted): 0.469\n",
            "  Total comparisons across groups: 194\n",
            "\n",
            "  Groups where 'o1' beats 'Command A' (2):\n",
            "    - White: 120 comparisons\n",
            "    - Mixed: 1 comparisons\n",
            "\n",
            "  Groups where 'Command A' beats 'o1' (2):\n",
            "    - Black: 30 comparisons\n",
            "    - Asian: 43 comparisons\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 3: Gemini 2.0 Flash vs Claude Sonnet 4\n",
            "  Inconsistency score (weighted): 0.455\n",
            "  Total comparisons across groups: 186\n",
            "\n",
            "  Groups where 'Gemini 2.0 Flash' beats 'Claude Sonnet 4' (2):\n",
            "    - Black: 48 comparisons\n",
            "    - Mixed: 17 comparisons\n",
            "\n",
            "  Groups where 'Claude Sonnet 4' beats 'Gemini 2.0 Flash' (2):\n",
            "    - White: 107 comparisons\n",
            "    - Asian: 14 comparisons\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 4: o3 mini vs Command R7B\n",
            "  Inconsistency score (weighted): 0.455\n",
            "  Total comparisons across groups: 438\n",
            "\n",
            "  Groups where 'o3 mini' beats 'Command R7B' (2):\n",
            "    - White: 254 comparisons\n",
            "    - Mixed: 31 comparisons\n",
            "\n",
            "  Groups where 'Command R7B' beats 'o3 mini' (2):\n",
            "    - Black: 25 comparisons\n",
            "    - Asian: 128 comparisons\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 5: Grok 3 vs Claude Opus 4\n",
            "  Inconsistency score (weighted): 0.432\n",
            "  Total comparisons across groups: 263\n",
            "\n",
            "  Groups where 'Grok 3' beats 'Claude Opus 4' (2):\n",
            "    - White: 151 comparisons\n",
            "    - Asian: 29 comparisons\n",
            "\n",
            "  Groups where 'Claude Opus 4' beats 'Grok 3' (2):\n",
            "    - Black: 55 comparisons\n",
            "    - Mixed: 28 comparisons\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 6: Mistral Nemo vs Command R7B\n",
            "  Inconsistency score (weighted): 0.423\n",
            "  Total comparisons across groups: 313\n",
            "\n",
            "  Groups where 'Mistral Nemo' beats 'Command R7B' (2):\n",
            "    - White: 180 comparisons\n",
            "    - Asian: 38 comparisons\n",
            "\n",
            "  Groups where 'Command R7B' beats 'Mistral Nemo' (2):\n",
            "    - Black: 59 comparisons\n",
            "    - Mixed: 36 comparisons\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 7: Grok 4 vs Claude Opus 4\n",
            "  Inconsistency score (weighted): 0.413\n",
            "  Total comparisons across groups: 161\n",
            "\n",
            "  Groups where 'Grok 4' beats 'Claude Opus 4' (1):\n",
            "    - Asian: 47 comparisons\n",
            "\n",
            "  Groups where 'Claude Opus 4' beats 'Grok 4' (2):\n",
            "    - White: 99 comparisons\n",
            "    - Black: 15 comparisons\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 8: o4 mini vs Claude 3.7 Sonnet\n",
            "  Inconsistency score (weighted): 0.407\n",
            "  Total comparisons across groups: 172\n",
            "\n",
            "  Groups where 'o4 mini' beats 'Claude 3.7 Sonnet' (1):\n",
            "    - Black: 49 comparisons\n",
            "\n",
            "  Groups where 'Claude 3.7 Sonnet' beats 'o4 mini' (3):\n",
            "    - White: 95 comparisons\n",
            "    - Asian: 23 comparisons\n",
            "    - Mixed: 5 comparisons\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 9: Grok 3 vs Gemini 2.5 Pro\n",
            "  Inconsistency score (weighted): 0.399\n",
            "  Total comparisons across groups: 211\n",
            "\n",
            "  Groups where 'Grok 3' beats 'Gemini 2.5 Pro' (2):\n",
            "    - Black: 51 comparisons\n",
            "    - Asian: 7 comparisons\n",
            "\n",
            "  Groups where 'Gemini 2.5 Pro' beats 'Grok 3' (2):\n",
            "    - White: 137 comparisons\n",
            "    - Mixed: 16 comparisons\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Rank 10: Mistral Nemo vs Claude 3.7 Sonnet\n",
            "  Inconsistency score (weighted): 0.385\n",
            "  Total comparisons across groups: 227\n",
            "\n",
            "  Groups where 'Mistral Nemo' beats 'Claude 3.7 Sonnet' (2):\n",
            "    - Black: 30 comparisons\n",
            "    - Asian: 29 comparisons\n",
            "\n",
            "  Groups where 'Claude 3.7 Sonnet' beats 'Mistral Nemo' (2):\n",
            "    - White: 157 comparisons\n",
            "    - Mixed: 11 comparisons\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def build_margins(df, groups, models, alpha=0.0, group_col=\"group\"):\n",
        "    m = len(models); K = len(groups)\n",
        "    idx = {name:i for i,name in enumerate(models)}\n",
        "    df = df[df[group_col].isin(groups)].copy()\n",
        "    df = df[df[\"model_a\"].isin(models) & df[\"model_b\"].isin(models)].copy()\n",
        "    counts = df[group_col].value_counts().reindex(groups).fillna(0).astype(int)\n",
        "    tot = int(counts.sum())\n",
        "    if tot == 0: raise ValueError(\"No rows after filtering; check groups/models.\")\n",
        "    w0 = (counts/tot).to_numpy(float)\n",
        "    \n",
        "    df = df.copy()\n",
        "    df[\"idx_a\"] = df[\"model_a\"].map(idx)\n",
        "    df[\"idx_b\"] = df[\"model_b\"].map(idx)\n",
        "    df = df.dropna(subset=[\"idx_a\", \"idx_b\"]).copy()\n",
        "    \n",
        "    M_list = []\n",
        "    T_list = [] \n",
        "    \n",
        "    for grp in groups:\n",
        "        rows = df[df[group_col]==grp]\n",
        "        if len(rows) == 0:\n",
        "            M_list.append(np.zeros((m,m), float))\n",
        "            T_list.append(np.zeros((m,m), float))  \n",
        "            continue\n",
        "        \n",
        "        win = np.zeros((m,m), float)\n",
        "        idx_a = rows[\"idx_a\"].values.astype(int)\n",
        "        idx_b = rows[\"idx_b\"].values.astype(int)\n",
        "        choice = rows[\"choice\"].values\n",
        "        \n",
        "        mask_a = (choice == \"A\")\n",
        "        np.add.at(win, (idx_a[mask_a], idx_b[mask_a]), 1.0)\n",
        "        mask_b = (choice == \"B\")\n",
        "        np.add.at(win, (idx_b[mask_b], idx_a[mask_b]), 1.0)\n",
        "\n",
        "        T = np.zeros((m, m), float)\n",
        "        for i in range(m):\n",
        "            for j in range(i+1, m):\n",
        "                tot_ij = win[i,j] + win[j,i]\n",
        "                T[i, j] = tot_ij\n",
        "                T[j, i] = tot_ij\n",
        "        T_list.append(T)\n",
        "        \n",
        "        M = np.zeros((m,m), float)\n",
        "        for i in range(m):\n",
        "            for j in range(i+1, m):\n",
        "                tot_ij = win[i,j] + win[j,i]\n",
        "                if tot_ij > 0:\n",
        "                    mij = (win[i,j] - win[j,i]) / (tot_ij + 2.0*alpha)\n",
        "                else:\n",
        "                    mij = 0.0\n",
        "                M[i,j] = mij; M[j,i] = -mij\n",
        "        M_list.append(M)\n",
        "    \n",
        "    return M_list, T_list, w0, counts, df \n",
        "\n",
        "def top_k_opposite_sign_details(\n",
        "    M_list: List[np.ndarray],\n",
        "    T_list: List[np.ndarray],\n",
        "    models: List[str],\n",
        "    groups: List[str],\n",
        "    k: int = 5,\n",
        "    model_shortcuts: Dict[str, str] = None\n",
        "):\n",
        "\n",
        "    if model_shortcuts is None:\n",
        "        model_shortcuts = {m: m for m in models}\n",
        "\n",
        "    n = len(models)\n",
        "    \n",
        "    if len(M_list) != len(groups) or len(T_list) != len(groups):\n",
        "        raise ValueError(\"M_list and T_list must have same length as groups\")\n",
        "\n",
        "    M_stack = np.stack(M_list, axis=0)\n",
        "    T_stack = np.stack(T_list, axis=0)  \n",
        "\n",
        "    Ts_total = T_stack.sum(axis=0) \n",
        "    pos_weights = np.where(M_stack > 0, T_stack, 0).sum(axis=0)\n",
        "    neg_weights = np.where(M_stack < 0, T_stack, 0).sum(axis=0)\n",
        "    \n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        p_pos = pos_weights / Ts_total\n",
        "        p_neg = neg_weights / Ts_total\n",
        "        prob_weighted = 2.0 * p_pos * p_neg\n",
        "    prob_weighted = np.nan_to_num(prob_weighted, nan=0.0)\n",
        "\n",
        "    mask_upper = np.triu(np.ones((n, n), dtype=bool))\n",
        "    candidate_mask = (~mask_upper) & (Ts_total > 0)  \n",
        "    flat_idx = np.where(candidate_mask.ravel())[0]\n",
        "    flat_probs = prob_weighted.ravel()[flat_idx]\n",
        "    \n",
        "    if flat_probs.size == 0:\n",
        "        print(\"No valid lower-triangle pairs with comparisons found.\")\n",
        "        return\n",
        "\n",
        "    top_k_idx = flat_idx[np.argsort(flat_probs)[::-1][:k]]\n",
        "    rows, cols = np.unravel_index(top_k_idx, (n, n))\n",
        "\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"TOP {k} MODEL PAIRS WITH MOST INCONSISTENT RANKINGS ACROSS GROUPS\")\n",
        "    print(f\"{'='*80}\\n\")\n",
        "\n",
        "    for rank, (i, j) in enumerate(zip(rows, cols), start=1):\n",
        "        prob_val = prob_weighted[i, j]\n",
        "        total_counts_ij = Ts_total[i, j]\n",
        "        \n",
        "        pos_grp_idx = np.where(M_stack[:, i, j] > 0)[0]\n",
        "        neg_grp_idx = np.where(M_stack[:, i, j] < 0)[0]\n",
        "        \n",
        "        pos_groups_list = [groups[g] for g in pos_grp_idx]\n",
        "        neg_groups_list = [groups[g] for g in neg_grp_idx]\n",
        "        \n",
        "        pos_counts_by_grp = {groups[g]: int(T_stack[g, i, j]) for g in pos_grp_idx}\n",
        "        neg_counts_by_grp = {groups[g]: int(T_stack[g, i, j]) for g in neg_grp_idx}\n",
        "\n",
        "        model_i_name = model_shortcuts.get(models[i], models[i])\n",
        "        model_j_name = model_shortcuts.get(models[j], models[j])\n",
        "\n",
        "        print(f\"Rank {rank}: {model_i_name} vs {model_j_name}\")\n",
        "        print(f\"  Inconsistency score (weighted): {prob_val:.3f}\")\n",
        "        print(f\"  Total comparisons across groups: {int(total_counts_ij)}\")\n",
        "        print(f\"\\n  Groups where '{model_i_name}' beats '{model_j_name}' ({len(pos_groups_list)}):\")\n",
        "        if pos_groups_list:\n",
        "            for grp in pos_groups_list:\n",
        "                print(f\"    - {grp}: {pos_counts_by_grp[grp]} comparisons\")\n",
        "        else:\n",
        "            print(\"    (none)\")\n",
        "        \n",
        "        print(f\"\\n  Groups where '{model_j_name}' beats '{model_i_name}' ({len(neg_groups_list)}):\")\n",
        "        if neg_groups_list:\n",
        "            for grp in neg_groups_list:\n",
        "                print(f\"    - {grp}: {neg_counts_by_grp[grp]} comparisons\")\n",
        "        else:\n",
        "            print(\"    (none)\")\n",
        "        print(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
        "\n",
        "\n",
        "df = load_df(group_by=GROUP_BY)\n",
        "M_list, T_list, w0, counts, df_filtered = build_margins(df, groups, MODELS, alpha=1.0, group_col=\"group\")\n",
        "\n",
        "model_shortcuts = {\n",
        "    'anthropic/claude-3.7-sonnet': 'Claude 3.7 Sonnet',\n",
        "    'anthropic/claude-opus-4': 'Claude Opus 4',\n",
        "    'anthropic/claude-sonnet-4': 'Claude Sonnet 4',\n",
        "    'cohere/command-a': 'Command A',\n",
        "    'cohere/command-r7b-12-2024': 'Command R7B',\n",
        "    'deepseek/deepseek-r1-0528': 'DeepSeek R1',\n",
        "    'google/gemini-2.0-flash-001': 'Gemini 2.0 Flash',\n",
        "    'google/gemini-2.5-flash': 'Gemini 2.5 Flash',\n",
        "    'google/gemini-2.5-pro': 'Gemini 2.5 Pro',\n",
        "    'mistralai/mistral-nemo': 'Mistral Nemo',\n",
        "    'openai/o1': 'o1',\n",
        "    'openai/o3-mini': 'o3 mini',\n",
        "    'openai/o4-mini': 'o4 mini',\n",
        "    'x-ai/grok-3': 'Grok 3',\n",
        "    'x-ai/grok-4': 'Grok 4',\n",
        "}\n",
        "\n",
        "top_k_opposite_sign_details(\n",
        "    M_list=M_list,\n",
        "    T_list=T_list,\n",
        "    models=MODELS,\n",
        "    groups=groups,\n",
        "    k=10,\n",
        "    model_shortcuts=model_shortcuts  # optional\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "30eb83b1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: heatmap_inconsistency_ethnic_group_ALPHA=1.0.pdf\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict, List, Tuple\n",
        "def plot_heatmap_inconsistency(\n",
        "    M_list: List[np.ndarray],\n",
        "    T_list: List[np.ndarray],\n",
        "    models: List[str],\n",
        "    groups: List[str],\n",
        "    model_shortcuts: Dict[str, str] = None,\n",
        "    out_pdf: str = None,\n",
        "    figsize: Tuple[int, int] = (12, 10),\n",
        "    annot_fontsize: int = 10,\n",
        "    cmap: str = \"Blues\",\n",
        "):\n",
        "\n",
        "    if out_pdf is None:\n",
        "        out_pdf = f\"heatmap_inconsistency_{GROUP_BY}_ALPHA={ALPHA}.pdf\"\n",
        "    \n",
        "    if model_shortcuts is None:\n",
        "        model_shortcuts = {m: m for m in models}\n",
        "    \n",
        "    n = len(models)\n",
        "    \n",
        "    M_stack = np.stack(M_list, axis=0)   \n",
        "    T_stack = np.stack(T_list, axis=0)   \n",
        "\n",
        "    Ts_total = T_stack.sum(axis=0)\n",
        "    pos_weights = np.where(M_stack > 0, T_stack, 0).sum(axis=0)\n",
        "    neg_weights = np.where(M_stack < 0, T_stack, 0).sum(axis=0)\n",
        "    \n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        p_pos = pos_weights / Ts_total\n",
        "        p_neg = neg_weights / Ts_total\n",
        "        prob_weighted = 2.0 * p_pos * p_neg\n",
        "    prob_weighted = np.nan_to_num(prob_weighted, nan=0.0)\n",
        "\n",
        "    W_overall = np.zeros((n, n), float)\n",
        "    T_overall = Ts_total.copy()\n",
        "    for k in range(len(M_list)):\n",
        "        W_overall += M_list[k] * T_list[k]\n",
        "    \n",
        "    winrates = []\n",
        "    for i in range(n):\n",
        "        total_wins = W_overall[i, :].sum()\n",
        "        total_comps = T_overall[i, :].sum()\n",
        "        winrates.append(total_wins / total_comps if total_comps > 0 else 0.0)\n",
        "    \n",
        "    sorted_indices = sorted(range(n), key=lambda i: (winrates[i], i), reverse=True)\n",
        "    sorted_models = [models[i] for i in sorted_indices]\n",
        "\n",
        "    prob_sorted = prob_weighted[np.ix_(sorted_indices, sorted_indices)]\n",
        "    T_sorted = T_overall[np.ix_(sorted_indices, sorted_indices)]\n",
        "    \n",
        "    mask = np.triu(np.ones((n, n), dtype=bool))\n",
        "    \n",
        "    annot = np.full(prob_sorted.shape, \"\", dtype=object)\n",
        "    eps = 1e-12\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if not mask[i, j] and T_sorted[i, j] > 0 and prob_sorted[i, j] > eps:\n",
        "                annot[i, j] = f\"{prob_sorted[i, j]:.2f}\"\n",
        "    \n",
        "\n",
        "    display_names = [model_shortcuts.get(model, model) for model in sorted_models]\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        \"font.size\": 10,\n",
        "        \"axes.labelsize\": 12,\n",
        "        \"xtick.labelsize\": 10,\n",
        "        \"ytick.labelsize\": 10,\n",
        "        \"pdf.fonttype\": 42,\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"font.family\": \"sans-serif\",\n",
        "    })\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    \n",
        "    global_vmax = prob_sorted.max() if prob_sorted.max() > 0 else 1.0\n",
        "    \n",
        "    sns.heatmap(\n",
        "        prob_sorted,\n",
        "        mask=mask,\n",
        "        xticklabels=display_names,\n",
        "        yticklabels=display_names,\n",
        "        cmap=cmap,\n",
        "        vmin=0.0,\n",
        "        vmax=global_vmax,\n",
        "        square=True,\n",
        "        cbar = False,\n",
        "        annot=annot,\n",
        "        fmt='',\n",
        "        annot_kws={'fontsize': annot_fontsize},\n",
        "        ax=ax\n",
        "    )\n",
        "    \n",
        "    ax.set_xlabel('Loser', fontsize=14)\n",
        "    ax.set_ylabel('Winner', fontsize=14)\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
        "    ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(out_pdf, dpi=300, bbox_inches='tight')\n",
        "    plt.close(fig)\n",
        "    print(f\"saved: {out_pdf}\")\n",
        "\n",
        "\n",
        "# Usage:\n",
        "plot_heatmap_inconsistency(\n",
        "    M_list=M_list,\n",
        "    T_list=T_list,\n",
        "    models=MODELS,\n",
        "    groups=groups,\n",
        "    model_shortcuts=model_shortcuts,\n",
        "    out_pdf=f\"heatmap_inconsistency_{GROUP_BY}_ALPHA={ALPHA}.pdf\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "buggy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
