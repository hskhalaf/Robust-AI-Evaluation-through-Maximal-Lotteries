{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "863c9bb2",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, cvxpy as cp\n",
        "from datasets import load_dataset\n",
        "import seaborn as sns\n",
        "import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "f8024677",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODELS = [\n",
        "'chatgpt-4o-latest-20250326','claude-3-5-haiku-20241022','claude-3-5-sonnet-20241022',\n",
        "'claude-3-7-sonnet-20250219','claude-3-7-sonnet-20250219-thinking-32k','claude-opus-4-20250514',\n",
        "'claude-opus-4-20250514-thinking-16k','claude-sonnet-4-20250514','claude-sonnet-4-20250514-thinking-32k',\n",
        "'deepseek-r1-0528','deepseek-v3-0324','gemini-2.0-flash-001','gemini-2.5-flash','gemini-2.5-pro',\n",
        "'gemma-3-27b-it','gpt-4.1-mini-2025-04-14','llama-4-maverick-03-26-experimental',\n",
        "'llama-4-maverick-17b-128e-instruct','mistral-medium-2505','o3-2025-04-16','o4-mini-2025-04-16',\n",
        "'qwen3-235b-a22b-no-thinking','qwen3-30b-a3b'\n",
        "]\n",
        "\n",
        "N_BOOT = 200\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "cca9e039",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_df():\n",
        "    ds = load_dataset(\"lmarena-ai/arena-human-preference-140k\", split=\"train\")\n",
        "    df = ds.to_pandas()\n",
        "    keep = ['model_a','model_b','winner','language','timestamp','is_code','category_tag']\n",
        "    return df[keep].copy()\n",
        "\n",
        "def top_languages(df, k=4):\n",
        "    vc = df[\"language\"].value_counts(dropna=False)\n",
        "    # Exclude \"und\" from the top k languages\n",
        "    vc_filtered = vc[vc.index != \"und\"]\n",
        "    langs = vc_filtered.head(k).index.tolist()\n",
        "    return langs, vc\n",
        "\n",
        "def build_margins(df, languages, models, alpha=1.0):\n",
        "    m = len(models); K = len(languages)\n",
        "    idx = {name:i for i,name in enumerate(models)}\n",
        "    df = df[df[\"language\"].isin(languages)].copy()\n",
        "    df = df[df[\"model_a\"].isin(models) & df[\"model_b\"].isin(models)].copy()\n",
        "    counts = df[\"language\"].value_counts().reindex(languages).fillna(0).astype(int)\n",
        "    tot = int(counts.sum())\n",
        "    if tot == 0: raise ValueError(\"No rows after filtering; check languages/models.\")\n",
        "    w0 = (counts/tot).to_numpy(float)\n",
        "\n",
        "    df = df.copy()\n",
        "    df[\"idx_a\"] = df[\"model_a\"].map(idx)\n",
        "    df[\"idx_b\"] = df[\"model_b\"].map(idx)\n",
        "    df = df.dropna(subset=[\"idx_a\", \"idx_b\"]).copy()\n",
        "    \n",
        "    M_list = []\n",
        "    for lang in languages:\n",
        "        rows = df[df[\"language\"]==lang]\n",
        "        if len(rows) == 0:\n",
        "            M_list.append(np.zeros((m,m), float))\n",
        "            continue\n",
        "        win = np.zeros((m,m), float)\n",
        "        idx_a = rows[\"idx_a\"].values.astype(int)\n",
        "        idx_b = rows[\"idx_b\"].values.astype(int)\n",
        "        winner = rows[\"winner\"].values\n",
        "        mask_a = (winner == \"model_a\")\n",
        "        np.add.at(win, (idx_a[mask_a], idx_b[mask_a]), 1.0)\n",
        "        mask_b = (winner == \"model_b\")\n",
        "        np.add.at(win, (idx_b[mask_b], idx_a[mask_b]), 1.0)\n",
        "\n",
        "        M = np.zeros((m,m), float)\n",
        "        for i in range(m):\n",
        "            for j in range(i+1, m):\n",
        "                tot_ij = win[i,j] + win[j,i]\n",
        "                if tot_ij > 0:\n",
        "                    mij = (win[i,j] - win[j,i]) / (tot_ij + 2.0*alpha)\n",
        "                else:\n",
        "                    mij = 0.0\n",
        "                M[i,j] = mij; M[j,i] = -mij\n",
        "        M_list.append(M)\n",
        "    return M_list, w0, counts, df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "2ca6dd21",
      "metadata": {},
      "outputs": [],
      "source": [
        "def solve_drml_tv(M_list, w0, rho, solvers=(\"GUROBI\",\"MOSEK\",\"GLPK\",\"ECOS\")):\n",
        "    K = len(M_list); m = M_list[0].shape[0]\n",
        "    p = cp.Variable(m, nonneg=True); t = cp.Variable()\n",
        "    mu = cp.Variable(m); lam = cp.Variable(m, nonneg=True)\n",
        "    gamma = cp.Variable((m,K))\n",
        "    cons = [cp.sum(p)==1]\n",
        "    for a in range(m):\n",
        "        cons += [t <= mu[a] - 2.0*rho*lam[a] + w0 @ gamma[a,:]]\n",
        "        for k in range(K):\n",
        "            Mk = M_list[k]\n",
        "            cons += [mu[a] + gamma[a,k] <= p @ Mk[:,a],\n",
        "                     gamma[a,k] <= lam[a],\n",
        "                     gamma[a,k] >= -lam[a]]\n",
        "    prob = cp.Problem(cp.Maximize(t), cons)\n",
        "    last = None\n",
        "    for s in solvers:\n",
        "        try:\n",
        "            prob.solve(solver=getattr(cp,s), verbose=False)\n",
        "            if prob.status in (\"optimal\",\"optimal_inaccurate\"): break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "    if prob.status not in (\"optimal\",\"optimal_inaccurate\"):\n",
        "        raise RuntimeError(f\"LP not solved. status={prob.status}, last={last}\")\n",
        "    pval = np.array(p.value).reshape(-1)\n",
        "    pval[pval<0]=0\n",
        "    if pval.sum()>0: pval /= pval.sum()\n",
        "    return pval, float(t.value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4f420bf9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def per_group_winrate(p, M_list):\n",
        "    M_stack = np.stack(M_list, axis=0)  # (K, m, m)\n",
        "    return per_group_winrate_vectorized(p, M_stack)\n",
        "\n",
        "def per_group_winrate_vectorized(p, M_stack):\n",
        "\n",
        "    pM = np.einsum('i,kij->kj', p, M_stack) \n",
        "    margins = np.min(pM, axis=1)  \n",
        "    wr = 0.5 * (1.0 + margins)\n",
        "    return wr\n",
        "\n",
        "def bootstrap_df(df_sub, languages, seed):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    parts = []\n",
        "    for lang in languages:\n",
        "        part = df_sub[df_sub[\"language\"]==lang]\n",
        "        n = len(part)\n",
        "        if n == 0: continue\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        parts.append(part.iloc[idx])\n",
        "    return pd.concat(parts, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "5709fdae",
      "metadata": {},
      "outputs": [],
      "source": [
        "def bootstrap_margins(df, models, n_boot=200, seed=0, alpha=1.0):\n",
        "    languages, _ = top_languages(df, k=4)\n",
        "    M0, w0, counts, df_sub = build_margins(df, languages, models, alpha=alpha)\n",
        "    print(\"languages:\", languages)\n",
        "    print(\"counts:\", dict(zip(languages, counts.tolist())))\n",
        "    print(\"w0:\", dict(zip(languages, w0.tolist())))\n",
        "    boot_M = []\n",
        "    for b in range(n_boot):\n",
        "        df_b = bootstrap_df(df_sub, languages, seed + 100000*b)\n",
        "        Mb, _, _, _ = build_margins(df_b, languages, models, alpha=alpha)\n",
        "        boot_M.append(Mb)\n",
        "        if (b+1) % max(1, n_boot//10) == 0: print(f\"boot {b+1}/{n_boot}\")\n",
        "    return languages, w0, M0, boot_M\n",
        "\n",
        "def compute_from_bootstrap(languages, w0, boot_M, rhos):\n",
        "    K = len(languages)\n",
        "    boot_wr = {(rho,k): [] for rho in rhos for k in range(K)}\n",
        "    boot_wr_overall = {rho: [] for rho in rhos}\n",
        "    boot_p = {rho: [] for rho in rhos}\n",
        "    boot_v = {rho: [] for rho in rhos}\n",
        "    n_boot = len(boot_M)\n",
        "    w0_arr = np.array(w0, float)\n",
        "    for b, Mb in enumerate(boot_M):\n",
        "        Mb_stack = np.stack(Mb, axis=0)\n",
        "        for rho in rhos:\n",
        "            p, v = solve_drml_tv(Mb, w0, rho)\n",
        "            boot_p[rho].append(p)\n",
        "            boot_v[rho].append(v)  \n",
        "            wr = per_group_winrate_vectorized(p, Mb_stack)\n",
        "            for k in range(K): boot_wr[(rho,k)].append(float(wr[k]))\n",
        "            M_pooled = np.einsum('k,kij->ij', w0_arr, Mb_stack)\n",
        "            overall_margin = float(np.min(p @ M_pooled))\n",
        "            overall_wr = 0.5 * (1 + overall_margin)\n",
        "            boot_wr_overall[rho].append(float(overall_wr))\n",
        "        if (b+1) % max(1, n_boot//10) == 0: print(f\"compute {b+1}/{n_boot}\")\n",
        "    rows = []\n",
        "    for rho in rhos:\n",
        "        for k, lang in enumerate(languages):\n",
        "            arr = np.array(boot_wr[(rho,k)], float)\n",
        "            se = float(arr.std() / np.sqrt(len(arr)))\n",
        "            rows.append({\"rho\": rho, \"group\": lang, \"boot_mean\": float(arr.mean()), \"boot_se\": se})\n",
        "        arr_overall = np.array(boot_wr_overall[rho], float)\n",
        "        se_overall = float(arr_overall.std() / np.sqrt(len(arr_overall)))\n",
        "        rows.append({\"rho\": rho, \"group\": \"overall\", \"boot_mean\": float(arr_overall.mean()), \"boot_se\": se_overall})\n",
        "    ci = pd.DataFrame(rows).sort_values([\"group\",\"rho\"])\n",
        "    return ci, boot_p, boot_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "f0782655",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating bootstrap margin matrices...\n",
            "languages: ['en', 'pl', 'ru', 'zh']\n",
            "counts: {'en': 26172, 'pl': 4842, 'ru': 3530, 'zh': 2565}\n",
            "w0: {'en': 0.7052736532916544, 'pl': 0.13048047643428817, 'ru': 0.09512517179120968, 'zh': 0.06912069848284783}\n",
            "boot 20/200\n",
            "boot 40/200\n",
            "boot 60/200\n",
            "boot 80/200\n",
            "boot 100/200\n",
            "boot 120/200\n",
            "boot 140/200\n",
            "boot 160/200\n",
            "boot 180/200\n",
            "boot 200/200\n"
          ]
        }
      ],
      "source": [
        "df = load_df()\n",
        "rhos = np.linspace(0.0, 1.0, 11)\n",
        "print(\"Generating bootstrap margin matrices...\")\n",
        "languages, w0, M0, boot_M = bootstrap_margins(df, MODELS, n_boot=N_BOOT, seed=1, alpha=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "1e90327b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing results from bootstrap margin matrices...\n",
            "compute 20/200\n",
            "compute 40/200\n",
            "compute 60/200\n",
            "compute 80/200\n",
            "compute 100/200\n",
            "compute 120/200\n",
            "compute 140/200\n",
            "compute 160/200\n",
            "compute 180/200\n",
            "compute 200/200\n"
          ]
        }
      ],
      "source": [
        "print(\"Computing results from bootstrap margin matrices...\")\n",
        "ci, boot_p, boot_v = compute_from_bootstrap(languages, w0, boot_M, rhos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "f363d730",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_group_curves(ci, languages, out_pdf=\"group_winrate_vs_rho.pdf\"):\n",
        "    lang_names = {'en': 'English', 'pl': 'Polish', 'ru': 'Russian', 'zh': 'Chinese', 'overall': 'Overall'}\n",
        "    \n",
        "    sns.set_style(\"whitegrid\")\n",
        "    sns.set_palette(\"husl\")\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        \"font.size\": 11,\n",
        "        \"axes.labelsize\": 12,\n",
        "        \"xtick.labelsize\": 10,\n",
        "        \"ytick.labelsize\": 10,\n",
        "        \"legend.fontsize\": 10,\n",
        "        \"pdf.fonttype\": 42,\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"axes.linewidth\": 0.8,\n",
        "        \"grid.linewidth\": 0.5,\n",
        "        \"xtick.major.width\": 0.6,\n",
        "        \"ytick.major.width\": 0.6,\n",
        "    })\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    \n",
        "    desired_order = ['overall', 'en', 'pl', 'zh', 'ru']\n",
        "    colors = {'overall': '#2C3E50', 'en': '#E74C3C', 'pl': '#3498DB', 'zh': '#F39C12', 'ru': '#27AE60'}\n",
        "    \n",
        "    for group in desired_order:\n",
        "        if group == 'overall':\n",
        "            d = ci[ci[\"group\"] == \"overall\"].sort_values(\"rho\")\n",
        "            if len(d) > 0:\n",
        "                x = d[\"rho\"].to_numpy(float)\n",
        "                y = d[\"boot_mean\"].to_numpy(float) * 100.0\n",
        "                se = d[\"boot_se\"].to_numpy(float) * 100.0\n",
        "                ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5, \n",
        "                       label=\"Overall\", linestyle=\"--\", color=colors['overall'], alpha=0.9)\n",
        "                ax.fill_between(x, y - se, y + se, alpha=0.15, color=colors['overall'])\n",
        "        elif group in languages:\n",
        "            d = ci[ci[\"group\"] == group].sort_values(\"rho\")\n",
        "            if len(d) > 0:\n",
        "                x = d[\"rho\"].to_numpy(float)\n",
        "                y = d[\"boot_mean\"].to_numpy(float) * 100.0\n",
        "                se = d[\"boot_se\"].to_numpy(float) * 100.0\n",
        "                lang_label = lang_names.get(group, group)\n",
        "                ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5, \n",
        "                       label=lang_label, color=colors[group], alpha=0.9)\n",
        "                ax.fill_between(x, y - se, y + se, alpha=0.15, color=colors[group])\n",
        "    \n",
        "    ax.set_xlabel(r\"$\\rho$\", fontsize=12, labelpad=6)\n",
        "    ax.set_ylabel(\"Win Rate (%)\", fontsize=12, labelpad=6)\n",
        "    \n",
        "    ax.grid(True, alpha=0.25, linestyle='-', linewidth=0.4)\n",
        "    ax.set_axisbelow(True)\n",
        "\n",
        "    ax.legend(frameon=True, loc='best', framealpha=0.95, facecolor='white', \n",
        "             edgecolor='lightgray', borderpad=0.8, labelspacing=0.6)\n",
        "\n",
        "    fig.tight_layout()\n",
        "    fig.savefig(out_pdf, bbox_inches=\"tight\", dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(\"saved:\", out_pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "19ef5268",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: group_winrate_vs_rho.pdf\n"
          ]
        }
      ],
      "source": [
        "plot_group_curves(ci, languages, out_pdf=\"group_winrate_vs_rho.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99edd17b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def bootstrap_train_test_splits(df, languages, models, train_frac=0.8, n_boot=100, seed=0):\n",
        "    df_filtered = df[df[\"language\"].isin(languages)].copy()\n",
        "    df_filtered = df_filtered[df_filtered[\"model_a\"].isin(models) & df_filtered[\"model_b\"].isin(models)].copy()\n",
        "    \n",
        "    splits = []\n",
        "    for b in range(n_boot):\n",
        "        rng = np.random.default_rng(seed + 100000*b)\n",
        "        n_total = len(df_filtered)\n",
        "        boot_idx = rng.integers(0, n_total, size=n_total)\n",
        "        df_boot = df_filtered.iloc[boot_idx].reset_index(drop=True)\n",
        "        \n",
        "        df_train_list = []\n",
        "        df_test_list = []\n",
        "        for lang in languages:\n",
        "            lang_df = df_boot[df_boot[\"language\"] == lang]\n",
        "            n = len(lang_df)\n",
        "            if n == 0:\n",
        "                continue\n",
        "            n_train = int(train_frac * n)\n",
        "            idx = np.arange(n)\n",
        "            rng.shuffle(idx)\n",
        "            train_idx = idx[:n_train]\n",
        "            test_idx = idx[n_train:]\n",
        "            df_train_list.append(lang_df.iloc[train_idx])\n",
        "            df_test_list.append(lang_df.iloc[test_idx])\n",
        "        if len(df_train_list) == 0:\n",
        "            continue\n",
        "        df_train = pd.concat(df_train_list, ignore_index=True)\n",
        "        df_test = pd.concat(df_test_list, ignore_index=True)\n",
        "        splits.append((df_train, df_test))\n",
        "        if (b+1) % max(1, n_boot//10) == 0: print(f\"boot {b+1}/{n_boot}\")\n",
        "    return splits\n",
        "\n",
        "def compute_generalization(splits, languages, models, rhos, alpha=1.0):\n",
        "    K = len(languages)\n",
        "    boot_wr_train = {(rho, lang): [] for rho in rhos for lang in languages + [\"overall\"]}\n",
        "    boot_wr_test = {(rho, lang): [] for rho in rhos for lang in languages + [\"overall\"]}\n",
        "    boot_wr_gap = {(rho, lang): [] for rho in rhos for lang in languages + [\"overall\"]}\n",
        "    \n",
        "    for df_train, df_test in splits:\n",
        "        M_train, w0_train, _, _ = build_margins(df_train, languages, models, alpha=alpha)\n",
        "        M_test, w0_test, _, _ = build_margins(df_test, languages, models, alpha=alpha)\n",
        "        \n",
        "        M_train_stack = np.stack(M_train, axis=0)\n",
        "        M_test_stack = np.stack(M_test, axis=0)\n",
        "        w0_train_arr = np.array(w0_train, float)\n",
        "        w0_test_arr = np.array(w0_test, float)\n",
        "        \n",
        "        for rho in rhos:\n",
        "            p_rho, _ = solve_drml_tv(M_train, w0_train, rho)\n",
        "            wr_train = per_group_winrate_vectorized(p_rho, M_train_stack)\n",
        "            wr_test = per_group_winrate_vectorized(p_rho, M_test_stack)\n",
        "            for k, lang in enumerate(languages):\n",
        "                boot_wr_train[(rho, lang)].append(float(wr_train[k]))\n",
        "                boot_wr_test[(rho, lang)].append(float(wr_test[k]))\n",
        "                boot_wr_gap[(rho, lang)].append(float(wr_test[k] - wr_train[k]))\n",
        "            \n",
        "            M_pooled_test = np.einsum('k,kij->ij', w0_test_arr, M_test_stack)\n",
        "            v_test_overall = float(np.min(p_rho @ M_pooled_test))\n",
        "            wr_test_overall = 0.5 * (1 + v_test_overall)\n",
        "            M_pooled_train = np.einsum('k,kij->ij', w0_train_arr, M_train_stack)\n",
        "            v_train_overall = float(np.min(p_rho @ M_pooled_train))\n",
        "            wr_train_overall = 0.5 * (1 + v_train_overall)\n",
        "            boot_wr_train[(rho, \"overall\")].append(float(wr_train_overall))\n",
        "            boot_wr_test[(rho, \"overall\")].append(float(wr_test_overall))\n",
        "            boot_wr_gap[(rho, \"overall\")].append(float(wr_test_overall - wr_train_overall))\n",
        "    \n",
        "    gap_rows = []\n",
        "    for rho in rhos:\n",
        "        for lang in languages + [\"overall\"]:\n",
        "            arr_train = np.array(boot_wr_train[(rho, lang)], float)\n",
        "            arr_test = np.array(boot_wr_test[(rho, lang)], float)\n",
        "            arr_gap = np.array(boot_wr_gap[(rho, lang)], float)\n",
        "            if len(arr_train) > 0:\n",
        "                gap_rows.append({\n",
        "                    \"rho\": rho,\n",
        "                    \"language\": lang,\n",
        "                    \"wr_train_mean\": float(arr_train.mean()),\n",
        "                    \"wr_train_se\": float(arr_train.std() / np.sqrt(len(arr_train))),\n",
        "                    \"wr_test_mean\": float(arr_test.mean()),\n",
        "                    \"wr_test_se\": float(arr_test.std() / np.sqrt(len(arr_test))),\n",
        "                    \"wr_gap_mean\": float(arr_gap.mean()),\n",
        "                    \"wr_gap_se\": float(arr_gap.std() / np.sqrt(len(arr_gap)))\n",
        "                })\n",
        "    gap_df = pd.DataFrame(gap_rows)\n",
        "    return gap_df, boot_wr_train, boot_wr_test, boot_wr_gap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "4370d5b9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating bootstrap train/test splits...\n",
            "boot 20/200\n",
            "boot 40/200\n",
            "boot 60/200\n",
            "boot 80/200\n",
            "boot 100/200\n",
            "boot 120/200\n",
            "boot 140/200\n",
            "boot 160/200\n",
            "boot 180/200\n",
            "boot 200/200\n"
          ]
        }
      ],
      "source": [
        "print(\"Generating bootstrap train/test splits...\")\n",
        "splits = bootstrap_train_test_splits(df, languages, MODELS, train_frac=0.8, n_boot=N_BOOT, seed=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "df2b138c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Computing generalization gaps from splits...\n"
          ]
        }
      ],
      "source": [
        "print(\"Computing generalization gaps from splits...\")\n",
        "gap_df, _, _, _ = compute_generalization(splits, languages, MODELS, rhos, alpha=1.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "fc44e342",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_generalization(gap_df, languages, metric=\"gap\", out_pdf=None):\n",
        "    lang_names = {'en': 'English', 'pl': 'Polish', 'ru': 'Russian', 'zh': 'Chinese', 'overall': 'Overall'}\n",
        "\n",
        "    if out_pdf is None:\n",
        "        out_pdf = f\"generalization_{metric}.pdf\"\n",
        "\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    sns.set_palette(\"husl\")\n",
        "\n",
        "    plt.rcParams.update({\n",
        "        \"font.size\": 11,\n",
        "        \"axes.labelsize\": 12,\n",
        "        \"xtick.labelsize\": 10,\n",
        "        \"ytick.labelsize\": 10,\n",
        "        \"legend.fontsize\": 10,\n",
        "        \"pdf.fonttype\": 42,\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"axes.linewidth\": 0.8,\n",
        "        \"grid.linewidth\": 0.5,\n",
        "        \"xtick.major.width\": 0.6,\n",
        "        \"ytick.major.width\": 0.6,\n",
        "    })\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    \n",
        "    desired_order = ['overall', 'en', 'pl', 'zh', 'ru']\n",
        "    colors = {'overall': '#2C3E50', 'en': '#E74C3C', 'pl': '#3498DB', 'zh': '#F39C12', 'ru': '#27AE60'}\n",
        "    \n",
        "    if metric == \"train\":\n",
        "        mean_col = \"wr_train_mean\"\n",
        "        se_col = \"wr_train_se\"\n",
        "        ylabel = \"Win rate on training data (%)\"\n",
        "        title_suffix = \"Train\"\n",
        "    elif metric == \"test\":\n",
        "        mean_col = \"wr_test_mean\"\n",
        "        se_col = \"wr_test_se\"\n",
        "        ylabel = \"Win rate on held out votes (%)\"\n",
        "        title_suffix = \"Test\"\n",
        "    elif metric == \"gap\":\n",
        "        mean_col = \"wr_gap_mean\"\n",
        "        se_col = \"wr_gap_se\"\n",
        "        ylabel = \"Win rate generalization gap (%)\"\n",
        "        title_suffix = \"Gap\"\n",
        "    else:\n",
        "        raise ValueError(\"metric must be 'train', 'test', or 'gap'\")\n",
        "    \n",
        "    if metric == \"gap\":\n",
        "        d = gap_df[gap_df[\"language\"] == \"overall\"].sort_values(\"rho\")\n",
        "        if len(d) > 0:\n",
        "            x = d[\"rho\"].to_numpy(float)\n",
        "            y = -d[mean_col].to_numpy(float) * 100.0\n",
        "            se = d[se_col].to_numpy(float) * 100.0\n",
        "            ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5,\n",
        "                   linestyle=\"-\", color=colors['overall'], alpha=0.9)\n",
        "            ax.fill_between(x, y - se, y + se, alpha=0.15, color=colors['overall'])\n",
        "    else:\n",
        "        for group in desired_order:\n",
        "                    d = gap_df[gap_df[\"language\"] == group].sort_values(\"rho\")\n",
        "                    if len(d) > 0:\n",
        "                        x = d[\"rho\"].to_numpy(float)\n",
        "                        y = d[mean_col].to_numpy(float) * 100.0\n",
        "                        se = d[se_col].to_numpy(float) * 100.0\n",
        "                        label = lang_names.get(group, group)\n",
        "                        linestyle = \"--\" if group == 'overall' else \"-\"\n",
        "                        ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5,\n",
        "                            label=label, linestyle=linestyle, color=colors[group], alpha=0.9)\n",
        "                        ax.fill_between(x, y - se, y + se, alpha=0.15, color=colors[group])\n",
        "        \n",
        "        ax.legend(frameon=True, loc='best', framealpha=0.95, facecolor='white', \n",
        "                 edgecolor='lightgray', borderpad=0.8, labelspacing=0.6)\n",
        "    \n",
        "    ax.set_xlabel(r\"$\\rho$\", fontsize=12, labelpad=6)\n",
        "    ax.set_ylabel(ylabel, fontsize=12, labelpad=6)\n",
        "    \n",
        "    ax.grid(True, alpha=0.25, linestyle='-', linewidth=0.4)\n",
        "    ax.set_axisbelow(True)\n",
        "    \n",
        "    fig.tight_layout()\n",
        "    fig.savefig(out_pdf, bbox_inches=\"tight\", dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(\"saved:\", out_pdf)\n",
        "\n",
        "def print_generalization_gaps(gap_df, languages, rhos):\n",
        "    lang_names = {'en': 'English', 'pl': 'Polish', 'ru': 'Russian', 'zh': 'Chinese', 'overall': 'Overall'}\n",
        "    gap_df = gap_df.copy()\n",
        "    gap_df[\"formatted\"] = gap_df.apply(\n",
        "        lambda row: f\"{row['wr_gap_mean']:.4f} ± {row['wr_gap_se']:.4f}\", axis=1\n",
        "    )\n",
        "    table = gap_df.pivot(index=\"language\", columns=\"rho\", values=\"formatted\")\n",
        "    all_langs = languages + [\"overall\"]\n",
        "    table = table.reindex(all_langs)\n",
        "    table.index = [lang_names.get(lang, lang) for lang in table.index]\n",
        "    display(table)\n",
        "    return table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "49b1605c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rho</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>English</th>\n",
              "      <td>-0.0774 ± 0.0047</td>\n",
              "      <td>-0.0735 ± 0.0041</td>\n",
              "      <td>-0.0633 ± 0.0036</td>\n",
              "      <td>-0.0553 ± 0.0032</td>\n",
              "      <td>-0.0467 ± 0.0030</td>\n",
              "      <td>-0.0420 ± 0.0028</td>\n",
              "      <td>-0.0365 ± 0.0027</td>\n",
              "      <td>-0.0333 ± 0.0028</td>\n",
              "      <td>-0.0305 ± 0.0027</td>\n",
              "      <td>-0.0285 ± 0.0026</td>\n",
              "      <td>-0.0279 ± 0.0026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Polish</th>\n",
              "      <td>-0.0631 ± 0.0079</td>\n",
              "      <td>-0.0595 ± 0.0070</td>\n",
              "      <td>-0.0541 ± 0.0066</td>\n",
              "      <td>-0.0488 ± 0.0056</td>\n",
              "      <td>-0.0473 ± 0.0048</td>\n",
              "      <td>-0.0480 ± 0.0043</td>\n",
              "      <td>-0.0505 ± 0.0039</td>\n",
              "      <td>-0.0503 ± 0.0035</td>\n",
              "      <td>-0.0501 ± 0.0032</td>\n",
              "      <td>-0.0488 ± 0.0031</td>\n",
              "      <td>-0.0485 ± 0.0031</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Russian</th>\n",
              "      <td>0.0062 ± 0.0065</td>\n",
              "      <td>0.0013 ± 0.0061</td>\n",
              "      <td>-0.0042 ± 0.0055</td>\n",
              "      <td>-0.0077 ± 0.0051</td>\n",
              "      <td>-0.0144 ± 0.0046</td>\n",
              "      <td>-0.0238 ± 0.0040</td>\n",
              "      <td>-0.0330 ± 0.0035</td>\n",
              "      <td>-0.0423 ± 0.0033</td>\n",
              "      <td>-0.0504 ± 0.0031</td>\n",
              "      <td>-0.0574 ± 0.0029</td>\n",
              "      <td>-0.0577 ± 0.0029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Chinese</th>\n",
              "      <td>0.0102 ± 0.0066</td>\n",
              "      <td>0.0035 ± 0.0064</td>\n",
              "      <td>-0.0052 ± 0.0056</td>\n",
              "      <td>-0.0154 ± 0.0045</td>\n",
              "      <td>-0.0216 ± 0.0039</td>\n",
              "      <td>-0.0264 ± 0.0037</td>\n",
              "      <td>-0.0306 ± 0.0034</td>\n",
              "      <td>-0.0317 ± 0.0031</td>\n",
              "      <td>-0.0329 ± 0.0030</td>\n",
              "      <td>-0.0350 ± 0.0028</td>\n",
              "      <td>-0.0362 ± 0.0028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Overall</th>\n",
              "      <td>-0.0597 ± 0.0033</td>\n",
              "      <td>-0.0528 ± 0.0029</td>\n",
              "      <td>-0.0457 ± 0.0027</td>\n",
              "      <td>-0.0390 ± 0.0024</td>\n",
              "      <td>-0.0324 ± 0.0023</td>\n",
              "      <td>-0.0289 ± 0.0021</td>\n",
              "      <td>-0.0254 ± 0.0020</td>\n",
              "      <td>-0.0225 ± 0.0020</td>\n",
              "      <td>-0.0196 ± 0.0020</td>\n",
              "      <td>-0.0186 ± 0.0020</td>\n",
              "      <td>-0.0182 ± 0.0020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "rho                   0.0               0.1               0.2  \\\n",
              "English  -0.0774 ± 0.0047  -0.0735 ± 0.0041  -0.0633 ± 0.0036   \n",
              "Polish   -0.0631 ± 0.0079  -0.0595 ± 0.0070  -0.0541 ± 0.0066   \n",
              "Russian   0.0062 ± 0.0065   0.0013 ± 0.0061  -0.0042 ± 0.0055   \n",
              "Chinese   0.0102 ± 0.0066   0.0035 ± 0.0064  -0.0052 ± 0.0056   \n",
              "Overall  -0.0597 ± 0.0033  -0.0528 ± 0.0029  -0.0457 ± 0.0027   \n",
              "\n",
              "rho                   0.3               0.4               0.5  \\\n",
              "English  -0.0553 ± 0.0032  -0.0467 ± 0.0030  -0.0420 ± 0.0028   \n",
              "Polish   -0.0488 ± 0.0056  -0.0473 ± 0.0048  -0.0480 ± 0.0043   \n",
              "Russian  -0.0077 ± 0.0051  -0.0144 ± 0.0046  -0.0238 ± 0.0040   \n",
              "Chinese  -0.0154 ± 0.0045  -0.0216 ± 0.0039  -0.0264 ± 0.0037   \n",
              "Overall  -0.0390 ± 0.0024  -0.0324 ± 0.0023  -0.0289 ± 0.0021   \n",
              "\n",
              "rho                   0.6               0.7               0.8  \\\n",
              "English  -0.0365 ± 0.0027  -0.0333 ± 0.0028  -0.0305 ± 0.0027   \n",
              "Polish   -0.0505 ± 0.0039  -0.0503 ± 0.0035  -0.0501 ± 0.0032   \n",
              "Russian  -0.0330 ± 0.0035  -0.0423 ± 0.0033  -0.0504 ± 0.0031   \n",
              "Chinese  -0.0306 ± 0.0034  -0.0317 ± 0.0031  -0.0329 ± 0.0030   \n",
              "Overall  -0.0254 ± 0.0020  -0.0225 ± 0.0020  -0.0196 ± 0.0020   \n",
              "\n",
              "rho                   0.9               1.0  \n",
              "English  -0.0285 ± 0.0026  -0.0279 ± 0.0026  \n",
              "Polish   -0.0488 ± 0.0031  -0.0485 ± 0.0031  \n",
              "Russian  -0.0574 ± 0.0029  -0.0577 ± 0.0029  \n",
              "Chinese  -0.0350 ± 0.0028  -0.0362 ± 0.0028  \n",
              "Overall  -0.0186 ± 0.0020  -0.0182 ± 0.0020  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: generalization.pdf\n",
            "saved: winrate_heldout.pdf\n"
          ]
        }
      ],
      "source": [
        "print_generalization_gaps(gap_df, languages, rhos)\n",
        "plot_generalization(gap_df, languages, \"gap\", out_pdf=\"generalization.pdf\")\n",
        "plot_generalization(gap_df, languages, \"test\", out_pdf=\"winrate_heldout.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "76d21a02",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(shown if mean> 2.0% for some rho)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rho</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gemini-2.5-pro</th>\n",
              "      <td>72.97 ± 2.56</td>\n",
              "      <td>69.73 ± 2.16</td>\n",
              "      <td>63.62 ± 1.87</td>\n",
              "      <td>57.76 ± 1.57</td>\n",
              "      <td>51.86 ± 1.33</td>\n",
              "      <td>46.65 ± 1.20</td>\n",
              "      <td>42.21 ± 1.10</td>\n",
              "      <td>39.11 ± 1.02</td>\n",
              "      <td>35.95 ± 0.98</td>\n",
              "      <td>34.64 ± 0.97</td>\n",
              "      <td>34.60 ± 0.96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chatgpt-4o-latest-20250326</th>\n",
              "      <td>11.53 ± 1.76</td>\n",
              "      <td>12.16 ± 1.49</td>\n",
              "      <td>12.25 ± 1.20</td>\n",
              "      <td>11.64 ± 1.04</td>\n",
              "      <td>10.51 ± 0.92</td>\n",
              "      <td>9.80 ± 0.88</td>\n",
              "      <td>9.66 ± 0.86</td>\n",
              "      <td>9.07 ± 0.79</td>\n",
              "      <td>8.69 ± 0.75</td>\n",
              "      <td>8.40 ± 0.73</td>\n",
              "      <td>8.33 ± 0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek-r1-0528</th>\n",
              "      <td>10.11 ± 1.48</td>\n",
              "      <td>11.35 ± 1.26</td>\n",
              "      <td>12.87 ± 1.11</td>\n",
              "      <td>13.39 ± 0.95</td>\n",
              "      <td>13.47 ± 0.91</td>\n",
              "      <td>13.13 ± 0.87</td>\n",
              "      <td>12.88 ± 0.81</td>\n",
              "      <td>12.37 ± 0.78</td>\n",
              "      <td>12.21 ± 0.77</td>\n",
              "      <td>12.19 ± 0.77</td>\n",
              "      <td>12.16 ± 0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>llama-4-maverick-03-26-experimental</th>\n",
              "      <td>2.73 ± 0.71</td>\n",
              "      <td>3.46 ± 0.70</td>\n",
              "      <td>5.31 ± 0.72</td>\n",
              "      <td>7.78 ± 0.77</td>\n",
              "      <td>10.65 ± 0.82</td>\n",
              "      <td>12.82 ± 0.86</td>\n",
              "      <td>14.25 ± 0.82</td>\n",
              "      <td>15.43 ± 0.83</td>\n",
              "      <td>15.88 ± 0.82</td>\n",
              "      <td>15.95 ± 0.82</td>\n",
              "      <td>16.01 ± 0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o3-2025-04-16</th>\n",
              "      <td>2.40 ± 0.61</td>\n",
              "      <td>2.91 ± 0.54</td>\n",
              "      <td>5.15 ± 0.65</td>\n",
              "      <td>7.92 ± 0.77</td>\n",
              "      <td>11.00 ± 0.90</td>\n",
              "      <td>13.56 ± 0.95</td>\n",
              "      <td>15.16 ± 0.98</td>\n",
              "      <td>16.11 ± 1.00</td>\n",
              "      <td>16.43 ± 0.95</td>\n",
              "      <td>15.84 ± 0.93</td>\n",
              "      <td>15.66 ± 0.93</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gemini-2.5-flash</th>\n",
              "      <td>0.09 ± 0.06</td>\n",
              "      <td>0.16 ± 0.08</td>\n",
              "      <td>0.26 ± 0.11</td>\n",
              "      <td>0.66 ± 0.20</td>\n",
              "      <td>1.04 ± 0.25</td>\n",
              "      <td>1.74 ± 0.31</td>\n",
              "      <td>2.58 ± 0.38</td>\n",
              "      <td>3.64 ± 0.45</td>\n",
              "      <td>5.04 ± 0.52</td>\n",
              "      <td>5.57 ± 0.55</td>\n",
              "      <td>5.66 ± 0.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qwen3-235b-a22b-no-thinking</th>\n",
              "      <td>0.00 ± 0.00</td>\n",
              "      <td>0.00 ± 0.00</td>\n",
              "      <td>0.00 ± 0.00</td>\n",
              "      <td>0.10 ± 0.04</td>\n",
              "      <td>0.50 ± 0.16</td>\n",
              "      <td>0.87 ± 0.22</td>\n",
              "      <td>1.41 ± 0.27</td>\n",
              "      <td>1.80 ± 0.27</td>\n",
              "      <td>2.41 ± 0.35</td>\n",
              "      <td>2.86 ± 0.36</td>\n",
              "      <td>2.90 ± 0.36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "rho                                           0.0           0.1           0.2  \\\n",
              "model                                                                           \n",
              "gemini-2.5-pro                       72.97 ± 2.56  69.73 ± 2.16  63.62 ± 1.87   \n",
              "chatgpt-4o-latest-20250326           11.53 ± 1.76  12.16 ± 1.49  12.25 ± 1.20   \n",
              "deepseek-r1-0528                     10.11 ± 1.48  11.35 ± 1.26  12.87 ± 1.11   \n",
              "llama-4-maverick-03-26-experimental   2.73 ± 0.71   3.46 ± 0.70   5.31 ± 0.72   \n",
              "o3-2025-04-16                         2.40 ± 0.61   2.91 ± 0.54   5.15 ± 0.65   \n",
              "gemini-2.5-flash                      0.09 ± 0.06   0.16 ± 0.08   0.26 ± 0.11   \n",
              "qwen3-235b-a22b-no-thinking           0.00 ± 0.00   0.00 ± 0.00   0.00 ± 0.00   \n",
              "\n",
              "rho                                           0.3           0.4           0.5  \\\n",
              "model                                                                           \n",
              "gemini-2.5-pro                       57.76 ± 1.57  51.86 ± 1.33  46.65 ± 1.20   \n",
              "chatgpt-4o-latest-20250326           11.64 ± 1.04  10.51 ± 0.92   9.80 ± 0.88   \n",
              "deepseek-r1-0528                     13.39 ± 0.95  13.47 ± 0.91  13.13 ± 0.87   \n",
              "llama-4-maverick-03-26-experimental   7.78 ± 0.77  10.65 ± 0.82  12.82 ± 0.86   \n",
              "o3-2025-04-16                         7.92 ± 0.77  11.00 ± 0.90  13.56 ± 0.95   \n",
              "gemini-2.5-flash                      0.66 ± 0.20   1.04 ± 0.25   1.74 ± 0.31   \n",
              "qwen3-235b-a22b-no-thinking           0.10 ± 0.04   0.50 ± 0.16   0.87 ± 0.22   \n",
              "\n",
              "rho                                           0.6           0.7           0.8  \\\n",
              "model                                                                           \n",
              "gemini-2.5-pro                       42.21 ± 1.10  39.11 ± 1.02  35.95 ± 0.98   \n",
              "chatgpt-4o-latest-20250326            9.66 ± 0.86   9.07 ± 0.79   8.69 ± 0.75   \n",
              "deepseek-r1-0528                     12.88 ± 0.81  12.37 ± 0.78  12.21 ± 0.77   \n",
              "llama-4-maverick-03-26-experimental  14.25 ± 0.82  15.43 ± 0.83  15.88 ± 0.82   \n",
              "o3-2025-04-16                        15.16 ± 0.98  16.11 ± 1.00  16.43 ± 0.95   \n",
              "gemini-2.5-flash                      2.58 ± 0.38   3.64 ± 0.45   5.04 ± 0.52   \n",
              "qwen3-235b-a22b-no-thinking           1.41 ± 0.27   1.80 ± 0.27   2.41 ± 0.35   \n",
              "\n",
              "rho                                           0.9           1.0  \n",
              "model                                                            \n",
              "gemini-2.5-pro                       34.64 ± 0.97  34.60 ± 0.96  \n",
              "chatgpt-4o-latest-20250326            8.40 ± 0.73   8.33 ± 0.72  \n",
              "deepseek-r1-0528                     12.19 ± 0.77  12.16 ± 0.76  \n",
              "llama-4-maverick-03-26-experimental  15.95 ± 0.82  16.01 ± 0.82  \n",
              "o3-2025-04-16                        15.84 ± 0.93  15.66 ± 0.93  \n",
              "gemini-2.5-flash                      5.57 ± 0.55   5.66 ± 0.55  \n",
              "qwen3-235b-a22b-no-thinking           2.86 ± 0.36   2.90 ± 0.36  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def print_boot_p(boot_p, models, rhos, thresh=0.02):\n",
        "    rows = []\n",
        "    for rho in rhos:\n",
        "        P = np.vstack(boot_p[rho])\n",
        "        mean = P.mean(axis=0)\n",
        "        se = P.std(axis=0) / np.sqrt(P.shape[0])\n",
        "        for i, name in enumerate(models):\n",
        "            rows.append({\"rho\": rho, \"model\": name, \"mean\": mean[i], \"se\": se[i]})\n",
        "    wdf = pd.DataFrame(rows)\n",
        "    keep = wdf.groupby(\"model\")[\"mean\"].max()\n",
        "    keep = keep[keep > thresh].index\n",
        "    wdf = wdf[wdf[\"model\"].isin(keep)].copy()\n",
        "    wdf[\"mean%\"] = (100*wdf[\"mean\"]).round(2)\n",
        "    wdf[\"se%\"] = (100*wdf[\"se\"]).round(2)\n",
        "    \n",
        "    wdf[\"formatted\"] = wdf.apply(lambda row: f\"{row['mean%']:.2f} ± {row['se%']:.2f}\", axis=1)\n",
        "    \n",
        "    table = wdf.pivot(index=\"model\", columns=\"rho\", values=\"formatted\")\n",
        "    \n",
        "    rho0_means = wdf[wdf[\"rho\"] == rhos[0]].set_index(\"model\")[\"mean\"].sort_values(ascending=False)\n",
        "    table = table.reindex(rho0_means.index)\n",
        "    \n",
        "    print(f\"(shown if mean> {100*thresh:.1f}% for some rho)\")\n",
        "    display(table)\n",
        "    return wdf\n",
        "\n",
        "wdf = print_boot_p(boot_p, MODELS, rhos, thresh=0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "9561cbea",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: model_performance_grid.pdf\n"
          ]
        }
      ],
      "source": [
        "def plot_model_performance_grid(wdf, out_pdf=\"model_performance_grid.pdf\"):\n",
        "    sns.set_style(\"white\")\n",
        "    \n",
        "    plt.rcParams.update({\n",
        "        \"font.size\": 13,\n",
        "        \"axes.labelsize\": 14,\n",
        "        \"xtick.labelsize\": 12,\n",
        "        \"ytick.labelsize\": 13,\n",
        "        \"legend.fontsize\": 13,\n",
        "        \"pdf.fonttype\": 42,\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"axes.linewidth\": 0.8,\n",
        "        \"grid.linewidth\": 0.4,\n",
        "        \"xtick.major.width\": 0.6,\n",
        "        \"ytick.major.width\": 0,\n",
        "    })\n",
        "    \n",
        "    model_names = {\n",
        "        'gemini-2.5-pro': 'Gemini 2.5 Pro',\n",
        "        'chatgpt-4o-latest-20250326': 'ChatGPT 4o',\n",
        "        'deepseek-r1-0528': 'DeepSeek R1',\n",
        "        'llama-4-maverick-03-26-experimental': 'Llama 4 Maverick',\n",
        "        'o3-2025-04-16': 'o3',\n",
        "        'gemini-2.5-flash': 'Gemini 2.5 Flash',\n",
        "        'qwen3-235b-a22b-no-thinking': 'Qwen 3 235B',\n",
        "    }\n",
        "    \n",
        "    colors = {\n",
        "        'gemini-2.5-pro': '#E74C3C',\n",
        "        'chatgpt-4o-latest-20250326': '#3498DB',\n",
        "        'deepseek-r1-0528': '#F39C12',\n",
        "        'llama-4-maverick-03-26-experimental': '#27AE60',\n",
        "        'o3-2025-04-16': '#9B59B6',\n",
        "        'gemini-2.5-flash': '#1ABC9C',\n",
        "        'qwen3-235b-a22b-no-thinking': '#E67E22',\n",
        "    }\n",
        "    \n",
        "    fig, axes = plt.subplots(1, 4, figsize=(18, 5))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    rhos_to_plot = [0.0, 0.4, 0.7, 1.0]\n",
        "    models_ordered = wdf[np.isclose(wdf[\"rho\"], 0.0)].sort_values(\"mean\", ascending=True)[\"model\"].values\n",
        "    \n",
        "    for idx, rho in enumerate(rhos_to_plot):\n",
        "        ax = axes[idx]\n",
        "        \n",
        "        data = wdf[np.isclose(wdf[\"rho\"], rho)].copy()\n",
        "        data = data.set_index(\"model\").reindex(models_ordered).reset_index()\n",
        "        data = data.dropna()\n",
        "        \n",
        "        bar_spacing = 0.65\n",
        "        y_pos = np.arange(len(data)) * bar_spacing\n",
        "        bar_colors = [colors.get(m, '#95A5A6') for m in data[\"model\"]]\n",
        "        \n",
        "        ax.barh(y_pos, data[\"mean%\"], xerr=data[\"se%\"], \n",
        "               color=bar_colors,\n",
        "               error_kw={'elinewidth': 1.2, 'capsize': 2.5, 'alpha': 0.7},\n",
        "               height=0.5 * bar_spacing, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
        "        \n",
        "        ax.set_xlim(0, 75)\n",
        "        ax.set_xticks([0, 20, 40, 60, 80])\n",
        "        ax.set_axisbelow(True)\n",
        "        ax.grid(True, axis='x', alpha=0.25, linestyle='-', linewidth=0.5, color='gray')\n",
        "        ax.grid(True, axis='y', alpha=0.15, linestyle='-', linewidth=0.3, color='gray')\n",
        "        \n",
        "        if idx == 0:\n",
        "            ax.set_yticks(y_pos)\n",
        "            clean_names = [model_names.get(m, m) for m in data[\"model\"]]\n",
        "            ax.set_yticklabels(clean_names, fontsize=13)\n",
        "        else:\n",
        "            ax.set_yticks([])\n",
        "        \n",
        "        ax.set_xlabel(\"Probability (%)\", fontsize=15, labelpad=4)\n",
        "        ax.set_xticklabels(['0', '20', '40', '60', '80'], fontsize=13)\n",
        "        \n",
        "        rho_label = f'ρ = {rho:.1f}'\n",
        "        ax.text(0.95, 0.1, rho_label, transform=ax.transAxes,\n",
        "               fontsize=18, fontweight='bold', ha='right', va='bottom',\n",
        "               bbox=dict(boxstyle='round,pad=0.4', facecolor='white', \n",
        "                        edgecolor='lightgray', alpha=0.8, linewidth=0.5))\n",
        "        \n",
        "        ax.spines['left'].set_linewidth(0.8)\n",
        "        ax.spines['bottom'].set_linewidth(0.8)\n",
        "        ax.spines['top'].set_visible(False)\n",
        "        ax.spines['right'].set_visible(False)\n",
        "    \n",
        "    fig.tight_layout(pad=1.2)\n",
        "    fig.savefig(out_pdf, bbox_inches=\"tight\", dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(f\"saved: {out_pdf}\")\n",
        "\n",
        "plot_model_performance_grid(wdf, out_pdf=\"model_performance_grid.pdf\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "buggy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
