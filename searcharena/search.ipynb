{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "863c9bb2",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniconda/base/envs/buggy/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np, pandas as pd, matplotlib.pyplot as plt, cvxpy as cp\n",
        "from datasets import load_dataset\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f8024677",
      "metadata": {},
      "outputs": [],
      "source": [
        "MODELS = ['gemini-2.0-flash-grounding', 'gemini-2.5-flash-preview-04-17-grounding', 'gemini-2.5-pro-exp-03-25-grounding', 'gemini-2.5-pro-exp-03-25-wo-search', 'gpt-4o-mini-search-preview', 'gpt-4o-search-preview', 'gpt-4o-search-preview-high', 'gpt-4o-search-preview-high-loc', 'sonar', 'sonar-pro', 'sonar-pro-high', 'sonar-reasoning', 'sonar-reasoning-pro-high']\n",
        "GROUP_BY = \"primary_intent\"  # Options: \"language\" or \"primary_intent\"\n",
        "N_BOOT = 200"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "cca9e039",
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_df(group_by=GROUP_BY):\n",
        "    ds = load_dataset(\"lmarena-ai/search-arena-24k\", split=\"test\")\n",
        "    df = ds.to_pandas()\n",
        "    keep = ['model_a','model_b','winner','languages','timestamp', 'primary_intent']\n",
        "    df = df[keep].copy()\n",
        "    # Filter rows where languages is a list with exactly one element\n",
        "    df = df[df[\"languages\"].apply(lambda x: isinstance(x, (list, tuple, np.ndarray)) and len(x) == 1)].copy()\n",
        "    def extract_lang(x):\n",
        "        if isinstance(x, (list, tuple, np.ndarray)) and len(x) == 1:\n",
        "            val = x[0]\n",
        "            if isinstance(val, np.ndarray):\n",
        "                val = val.item() if val.size == 1 else str(val[0])\n",
        "            return str(val)\n",
        "        return str(x)\n",
        "    df[\"language\"] = df[\"languages\"].apply(extract_lang)\n",
        "    if group_by == \"language\":\n",
        "        df[\"group\"] = df[\"language\"]\n",
        "    elif group_by == \"primary_intent\":\n",
        "        df[\"group\"] = df[\"primary_intent\"]\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown group_by: {group_by}. Must be 'language' or 'primary_intent'\")\n",
        "    return df\n",
        "\n",
        "def top_groups(df, group_col=\"group\", k=4):\n",
        "    vc = df[group_col].value_counts(dropna=False)\n",
        "    groups = vc.head(k).index.tolist()\n",
        "    print(groups)\n",
        "    return groups, vc\n",
        "\n",
        "def top_languages(df, k=4):\n",
        "    return top_groups(df, \"language\", k)\n",
        "\n",
        "\n",
        "def build_margins(df, groups, models, alpha=1.0, group_col=\"group\"):\n",
        "    m = len(models); K = len(groups)\n",
        "    idx = {name:i for i,name in enumerate(models)}\n",
        "    df = df[df[group_col].isin(groups)].copy()\n",
        "    df = df[df[\"model_a\"].isin(models) & df[\"model_b\"].isin(models)].copy()\n",
        "    counts = df[group_col].value_counts().reindex(groups).fillna(0).astype(int)\n",
        "    tot = int(counts.sum())\n",
        "    if tot == 0: raise ValueError(\"No rows after filtering; check groups/models.\")\n",
        "    w0 = (counts/tot).to_numpy(float)\n",
        "    M_list = []\n",
        "    df = df.copy()\n",
        "    df[\"idx_a\"] = df[\"model_a\"].map(idx)\n",
        "    df[\"idx_b\"] = df[\"model_b\"].map(idx)\n",
        "    df = df.dropna(subset=[\"idx_a\", \"idx_b\"]).copy()\n",
        "    \n",
        "    M_list = []\n",
        "    for grp in groups:\n",
        "        rows = df[df[group_col]==grp]\n",
        "        if len(rows) == 0:\n",
        "            M_list.append(np.zeros((m,m), float))\n",
        "            continue\n",
        "        win = np.zeros((m,m), float)\n",
        "        idx_a = rows[\"idx_a\"].values.astype(int)\n",
        "        idx_b = rows[\"idx_b\"].values.astype(int)\n",
        "        winner = rows[\"winner\"].values\n",
        "        mask_a = (winner == \"model_a\")\n",
        "        np.add.at(win, (idx_a[mask_a], idx_b[mask_a]), 1.0)\n",
        "        mask_b = (winner == \"model_b\")\n",
        "        np.add.at(win, (idx_b[mask_b], idx_a[mask_b]), 1.0)\n",
        "\n",
        "        M = np.zeros((m,m), float)\n",
        "        for i in range(m):\n",
        "            for j in range(i+1, m):\n",
        "                tot_ij = win[i,j] + win[j,i]\n",
        "                if tot_ij > 0:\n",
        "                    mij = (win[i,j] - win[j,i]) / (tot_ij + 2.0*alpha)\n",
        "                else:\n",
        "                    mij = 0.0\n",
        "                M[i,j] = mij; M[j,i] = -mij\n",
        "        M_list.append(M)\n",
        "    return M_list, w0, counts, df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "2ca6dd21",
      "metadata": {},
      "outputs": [],
      "source": [
        "def solve_drml_tv(M_list, w0, rho, solvers=(\"GUROBI\",\"MOSEK\",\"GLPK\",\"ECOS\")):\n",
        "    K = len(M_list); m = M_list[0].shape[0]\n",
        "    p = cp.Variable(m, nonneg=True); t = cp.Variable()\n",
        "    mu = cp.Variable(m); lam = cp.Variable(m, nonneg=True)\n",
        "    gamma = cp.Variable((m,K))\n",
        "    cons = [cp.sum(p)==1]\n",
        "    for a in range(m):\n",
        "        cons += [t <= mu[a] - 2.0*rho*lam[a] + w0 @ gamma[a,:]]\n",
        "        for k in range(K):\n",
        "            Mk = M_list[k]\n",
        "            cons += [mu[a] + gamma[a,k] <= p @ Mk[:,a],\n",
        "                     gamma[a,k] <= lam[a],\n",
        "                     gamma[a,k] >= -lam[a]]\n",
        "    prob = cp.Problem(cp.Maximize(t), cons)\n",
        "    last = None\n",
        "    for s in solvers:\n",
        "        try:\n",
        "            prob.solve(solver=getattr(cp,s), verbose=False)\n",
        "            if prob.status in (\"optimal\",\"optimal_inaccurate\"): break\n",
        "        except Exception as e:\n",
        "            last = e\n",
        "    if prob.status not in (\"optimal\",\"optimal_inaccurate\"):\n",
        "        raise RuntimeError(f\"LP not solved. status={prob.status}, last={last}\")\n",
        "    pval = np.array(p.value).reshape(-1)\n",
        "    pval[pval<0]=0\n",
        "    if pval.sum()>0: pval /= pval.sum()\n",
        "    return pval, float(t.value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4f420bf9",
      "metadata": {},
      "outputs": [],
      "source": [
        "def per_group_winrate(p, M_list):\n",
        "    M_stack = np.stack(M_list, axis=0)  # (K, m, m)\n",
        "    return per_group_winrate_vectorized(p, M_stack)\n",
        "\n",
        "def per_group_winrate_vectorized(p, M_stack):\n",
        "    pM = np.einsum('i,kij->kj', p, M_stack)\n",
        "    margins = np.min(pM, axis=1)\n",
        "    wr = 0.5 * (1.0 + margins)\n",
        "    return wr\n",
        "\n",
        "def bootstrap_df(df_sub, groups, seed, group_col=\"group\"):\n",
        "    rng = np.random.default_rng(seed)\n",
        "    parts = []\n",
        "    for grp in groups:\n",
        "        part = df_sub[df_sub[group_col]==grp]\n",
        "        n = len(part)\n",
        "        if n == 0: continue\n",
        "        idx = rng.integers(0, n, size=n)\n",
        "        parts.append(part.iloc[idx])\n",
        "    return pd.concat(parts, ignore_index=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5709fdae",
      "metadata": {},
      "outputs": [],
      "source": [
        "def bootstrap_margins(df, models, n_boot=200, seed=0, alpha=1.0, group_by=GROUP_BY):\n",
        "    if group_by == \"language\":\n",
        "        df[\"group\"] = df[\"language\"]\n",
        "        groups, _ = top_groups(df, \"group\", k=4)\n",
        "    elif group_by == \"primary_intent\":\n",
        "        df[\"group\"] = df[\"primary_intent\"]\n",
        "        groups, _ = top_groups(df, \"group\", k=4)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown group_by: {group_by}\")\n",
        "\n",
        "    M0, w0, counts, df_sub = build_margins(df, groups, models, alpha=alpha, group_col=\"group\")\n",
        "    print(\"groups:\", groups)\n",
        "    print(\"counts:\", dict(zip(groups, counts.tolist())))\n",
        "    print(\"w0:\", dict(zip(groups, w0.tolist())))\n",
        "    boot_M = []\n",
        "    for b in range(n_boot):\n",
        "        df_b = bootstrap_df(df_sub, groups, seed + 100000*b, group_col=\"group\")\n",
        "        Mb, _, _, _ = build_margins(df_b, groups, models, alpha=alpha, group_col=\"group\")\n",
        "        boot_M.append(Mb)\n",
        "        if (b+1) % max(1, n_boot//10) == 0: print(f\"boot {b+1}/{n_boot}\")\n",
        "    return groups, w0, M0, boot_M\n",
        "\n",
        "def compute_from_bootstrap(groups, w0, boot_M, rhos):\n",
        "    K = len(groups)\n",
        "    boot_wr = {(rho,k): [] for rho in rhos for k in range(K)}\n",
        "    boot_wr_overall = {rho: [] for rho in rhos}\n",
        "    boot_p = {rho: [] for rho in rhos}\n",
        "    boot_v = {rho: [] for rho in rhos}\n",
        "    n_boot = len(boot_M)\n",
        "    w0_arr = np.array(w0, float)\n",
        "    for b, Mb in enumerate(boot_M):\n",
        "        Mb_stack = np.stack(Mb, axis=0)\n",
        "        for rho in rhos:\n",
        "            p, v = solve_drml_tv(Mb, w0, rho)\n",
        "            boot_p[rho].append(p)\n",
        "            boot_v[rho].append(v)  \n",
        "            wr = per_group_winrate_vectorized(p, Mb_stack)\n",
        "            for k in range(K): boot_wr[(rho,k)].append(float(wr[k]))\n",
        "            M_pooled = np.einsum('k,kij->ij', w0_arr, Mb_stack)\n",
        "            overall_margin = float(np.min(p @ M_pooled))\n",
        "            overall_wr = 0.5 * (1 + overall_margin)\n",
        "            boot_wr_overall[rho].append(float(overall_wr))\n",
        "        if (b+1) % max(1, n_boot//10) == 0: print(f\"compute {b+1}/{n_boot}\")\n",
        "    rows = []\n",
        "    for rho in rhos:\n",
        "        for k, lang in enumerate(groups):\n",
        "            arr = np.array(boot_wr[(rho,k)], float)\n",
        "            se = float(arr.std() / np.sqrt(len(arr)))\n",
        "            rows.append({\"rho\": rho, \"group\": lang, \"boot_mean\": float(arr.mean()), \"boot_se\": se})\n",
        "        arr_overall = np.array(boot_wr_overall[rho], float)\n",
        "        se_overall = float(arr_overall.std() / np.sqrt(len(arr_overall)))\n",
        "        rows.append({\"rho\": rho, \"group\": \"overall\", \"boot_mean\": float(arr_overall.mean()), \"boot_se\": se_overall})\n",
        "    ci = pd.DataFrame(rows).sort_values([\"group\",\"rho\"])\n",
        "    return ci, boot_p, boot_v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f0782655",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating bootstrap margin matrices...\n",
            "['Factual Lookup', 'Info Synthesis', 'Recommendation', 'Analysis']\n",
            "groups: ['Factual Lookup', 'Info Synthesis', 'Recommendation', 'Analysis']\n",
            "counts: {'Factual Lookup': 4269, 'Info Synthesis': 3931, 'Recommendation': 2441, 'Analysis': 2348}\n",
            "w0: {'Factual Lookup': 0.3286627146046655, 'Info Synthesis': 0.30264069597351606, 'Recommendation': 0.18792824697821234, 'Analysis': 0.18076834244360612}\n",
            "boot 20/200\n",
            "boot 40/200\n",
            "boot 60/200\n",
            "boot 80/200\n",
            "boot 100/200\n",
            "boot 120/200\n",
            "boot 140/200\n",
            "boot 160/200\n",
            "boot 180/200\n",
            "boot 200/200\n",
            "Computing results from bootstrap margin matrices...\n",
            "compute 20/200\n",
            "compute 40/200\n",
            "compute 60/200\n",
            "compute 80/200\n",
            "compute 100/200\n",
            "compute 120/200\n",
            "compute 140/200\n",
            "compute 160/200\n",
            "compute 180/200\n",
            "compute 200/200\n"
          ]
        }
      ],
      "source": [
        "df = load_df(group_by=GROUP_BY)\n",
        "rhos = np.linspace(0.0, 1.0, 11)\n",
        "print(\"Generating bootstrap margin matrices...\")\n",
        "groups, w0, M0, boot_M = bootstrap_margins(df, MODELS, n_boot=N_BOOT, seed=1, alpha=1.0, group_by=GROUP_BY)\n",
        "print(\"Computing results from bootstrap margin matrices...\")\n",
        "ci, boot_p, boot_v = compute_from_bootstrap(groups, w0, boot_M, rhos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "f363d730",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_group_curves(ci, groups, out_pdf=None):\n",
        "    if out_pdf is None:\n",
        "        out_pdf = f\"group_winrate_vs_rho_{GROUP_BY}.pdf\"\n",
        "    sns.set_style(\"whitegrid\")\n",
        "    sns.set_palette(\"husl\")\n",
        "    \n",
        "    plt.rcParams.update({\n",
        "        \"font.size\": 11,\n",
        "        \"axes.labelsize\": 12,\n",
        "        \"xtick.labelsize\": 10,\n",
        "        \"ytick.labelsize\": 10,\n",
        "        \"legend.fontsize\": 10,\n",
        "        \"pdf.fonttype\": 42,\n",
        "        \"ps.fonttype\": 42,\n",
        "        \"font.family\": \"sans-serif\",\n",
        "        \"axes.linewidth\": 0.8,\n",
        "        \"grid.linewidth\": 0.5,\n",
        "        \"xtick.major.width\": 0.6,\n",
        "        \"ytick.major.width\": 0.6,\n",
        "    })\n",
        "    \n",
        "    fig, ax = plt.subplots(figsize=(6, 4))\n",
        "    \n",
        "    default_colors = ['#E74C3C', '#3498DB', '#F39C12', '#27AE60', '#9B59B6', '#1ABC9C', '#E67E22']\n",
        "    colors = {'overall': '#2C3E50'}\n",
        "    for i, grp in enumerate(groups):\n",
        "        if grp not in colors:\n",
        "            colors[grp] = default_colors[i % len(default_colors)]\n",
        "    \n",
        "    desired_order = ['overall'] + list(groups)\n",
        "    \n",
        "    for group in desired_order:\n",
        "        if group == 'overall':\n",
        "            d = ci[ci[\"group\"] == \"overall\"].sort_values(\"rho\")\n",
        "            if len(d) > 0:\n",
        "                x = d[\"rho\"].to_numpy(float)\n",
        "                y = d[\"boot_mean\"].to_numpy(float)\n",
        "                se = d[\"boot_se\"].to_numpy(float)\n",
        "                ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5, \n",
        "                       label=\"Overall\", linestyle=\"--\", color=colors['overall'], alpha=0.9)\n",
        "                ax.fill_between(x, y - se, y + se, alpha=0.15, color=colors['overall'])\n",
        "        elif group in groups:\n",
        "            d = ci[ci[\"group\"] == group].sort_values(\"rho\")\n",
        "            if len(d) > 0:\n",
        "                x = d[\"rho\"].to_numpy(float)\n",
        "                y = d[\"boot_mean\"].to_numpy(float)\n",
        "                se = d[\"boot_se\"].to_numpy(float)\n",
        "                ax.plot(x, y, marker=\"o\", linewidth=1.2, markersize=5, \n",
        "                       label=group, color=colors.get(group, '#95A5A6'), alpha=0.9)\n",
        "                ax.fill_between(x, y - se, y + se, alpha=0.15, color=colors.get(group, '#95A5A6'))\n",
        "    \n",
        "    ax.set_xlabel(r\"$\\rho$\", fontsize=12, labelpad=6)\n",
        "    ax.set_ylabel(\"Win Rate (%)\", fontsize=12, labelpad=6)\n",
        "    \n",
        "    ax.grid(True, alpha=0.25, linestyle='-', linewidth=0.4)\n",
        "    ax.set_axisbelow(True)\n",
        "    \n",
        "    ax.legend(frameon=True, loc='best', framealpha=0.95, facecolor='white', \n",
        "             edgecolor='lightgray', borderpad=0.8, labelspacing=0.6)\n",
        "    \n",
        "    fig.tight_layout()\n",
        "    fig.savefig(out_pdf, bbox_inches=\"tight\", dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(\"saved:\", out_pdf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "19ef5268",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: group_winrate_vs_rho_primary_intent.pdf\n"
          ]
        }
      ],
      "source": [
        "plot_group_curves(ci, groups)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "99edd17b",
      "metadata": {},
      "outputs": [],
      "source": [
        "def bootstrap_train_test_splits(\n",
        "    df,\n",
        "    groups,\n",
        "    models,\n",
        "    train_frac=0.8,\n",
        "    n_boot=100,\n",
        "    seed=0,\n",
        "    group_col=\"group\",\n",
        "):\n",
        "    df_filtered = df[df[group_col].isin(groups)].copy()\n",
        "    df_filtered = df_filtered[\n",
        "        df_filtered[\"model_a\"].isin(models) & df_filtered[\"model_b\"].isin(models)\n",
        "    ].copy()\n",
        "\n",
        "    splits = []\n",
        "    for b in range(n_boot):\n",
        "        rng = np.random.default_rng(seed + 100000 * b)\n",
        "        n_total = len(df_filtered)\n",
        "        boot_idx = rng.integers(0, n_total, size=n_total)\n",
        "        df_boot = df_filtered.iloc[boot_idx].reset_index(drop=True)\n",
        "\n",
        "        df_train_list = []\n",
        "        df_test_list = []\n",
        "        for grp in groups:\n",
        "            grp_df = df_boot[df_boot[group_col] == grp]\n",
        "            n = len(grp_df)\n",
        "            if n == 0:\n",
        "                continue\n",
        "            n_train = int(train_frac * n)\n",
        "            idx = np.arange(n)\n",
        "            rng.shuffle(idx)\n",
        "            train_idx = idx[:n_train]\n",
        "            test_idx = idx[n_train:]\n",
        "            df_train_list.append(grp_df.iloc[train_idx])\n",
        "            df_test_list.append(grp_df.iloc[test_idx])\n",
        "\n",
        "        if len(df_train_list) == 0:\n",
        "            continue\n",
        "\n",
        "        df_train = pd.concat(df_train_list, ignore_index=True)\n",
        "        df_test = pd.concat(df_test_list, ignore_index=True)\n",
        "        splits.append((df_train, df_test))\n",
        "\n",
        "        if (b + 1) % max(1, n_boot // 10) == 0:\n",
        "            print(f\"boot {b+1}/{n_boot}\")\n",
        "\n",
        "    return splits\n",
        "\n",
        "\n",
        "def compute_generalization(\n",
        "    splits,\n",
        "    groups,\n",
        "    models,\n",
        "    rhos,\n",
        "    alpha=1.0,\n",
        "    group_col=\"group\",\n",
        "):\n",
        "    K = len(groups)\n",
        "\n",
        "    # store train/test/gap for each (rho, group) and \"overall\"\n",
        "    boot_wr_train = {(rho, grp): [] for rho in rhos for grp in groups + [\"overall\"]}\n",
        "    boot_wr_test  = {(rho, grp): [] for rho in rhos for grp in groups + [\"overall\"]}\n",
        "    boot_wr_gap   = {(rho, grp): [] for rho in rhos for grp in groups + [\"overall\"]}\n",
        "\n",
        "    for df_train, df_test in splits:\n",
        "        M_train, w0_train, _, _ = build_margins(\n",
        "            df_train, groups, models, alpha=alpha, group_col=group_col\n",
        "        )\n",
        "        M_test, w0_test, _, _ = build_margins(\n",
        "            df_test, groups, models, alpha=alpha, group_col=group_col\n",
        "        )\n",
        "\n",
        "        M_train_stack = np.stack(M_train, axis=0)\n",
        "        M_test_stack = np.stack(M_test, axis=0)\n",
        "        w0_train_arr = np.array(w0_train, float)\n",
        "        w0_test_arr = np.array(w0_test, float)\n",
        "\n",
        "        for rho in rhos:\n",
        "            p_rho, _ = solve_drml_tv(M_train, w0_train, rho)\n",
        "\n",
        "            # per-group train/test winrates under p_rho\n",
        "            wr_train = per_group_winrate_vectorized(p_rho, M_train_stack)\n",
        "            wr_test = per_group_winrate_vectorized(p_rho, M_test_stack)\n",
        "\n",
        "            for k, grp in enumerate(groups):\n",
        "                boot_wr_train[(rho, grp)].append(float(wr_train[k]))\n",
        "                boot_wr_test[(rho, grp)].append(float(wr_test[k]))\n",
        "                boot_wr_gap[(rho, grp)].append(float(wr_test[k] - wr_train[k]))\n",
        "\n",
        "            # overall (pooled by w0) train/test winrates\n",
        "            M_pooled_train = np.einsum(\"k,kij->ij\", w0_train_arr, M_train_stack)\n",
        "            v_train_overall = float(np.min(p_rho @ M_pooled_train))\n",
        "            wr_train_overall = 0.5 * (1 + v_train_overall)\n",
        "\n",
        "            M_pooled_test = np.einsum(\"k,kij->ij\", w0_test_arr, M_test_stack)\n",
        "            v_test_overall = float(np.min(p_rho @ M_pooled_test))\n",
        "            wr_test_overall = 0.5 * (1 + v_test_overall)\n",
        "\n",
        "            boot_wr_train[(rho, \"overall\")].append(float(wr_train_overall))\n",
        "            boot_wr_test[(rho, \"overall\")].append(float(wr_test_overall))\n",
        "            boot_wr_gap[(rho, \"overall\")].append(float(wr_test_overall - wr_train_overall))\n",
        "\n",
        "    # summarize means + SEs\n",
        "    rows = []\n",
        "    for rho in rhos:\n",
        "        for grp in groups + [\"overall\"]:\n",
        "            arr_train = np.array(boot_wr_train[(rho, grp)], float)\n",
        "            arr_test = np.array(boot_wr_test[(rho, grp)], float)\n",
        "            arr_gap = np.array(boot_wr_gap[(rho, grp)], float)\n",
        "\n",
        "            if len(arr_train) == 0:\n",
        "                continue\n",
        "\n",
        "            n = len(arr_train)\n",
        "            rows.append(\n",
        "                {\n",
        "                    \"rho\": rho,\n",
        "                    \"group\": grp,\n",
        "                    \"wr_train_mean\": float(arr_train.mean()),\n",
        "                    \"wr_train_se\": float(arr_train.std(ddof=0) / np.sqrt(n)),\n",
        "                    \"wr_test_mean\": float(arr_test.mean()),\n",
        "                    \"wr_test_se\": float(arr_test.std(ddof=0) / np.sqrt(n)),\n",
        "                    \"wr_gap_mean\": float(arr_gap.mean()),\n",
        "                    \"wr_gap_se\": float(arr_gap.std(ddof=0) / np.sqrt(n)),\n",
        "                }\n",
        "            )\n",
        "\n",
        "    gap_df = pd.DataFrame(rows)\n",
        "    return gap_df, boot_wr_train, boot_wr_test, boot_wr_gap\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "df2b138c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating bootstrap train/test splits...\n",
            "boot 20/200\n",
            "boot 40/200\n",
            "boot 60/200\n",
            "boot 80/200\n",
            "boot 100/200\n",
            "boot 120/200\n",
            "boot 140/200\n",
            "boot 160/200\n",
            "boot 180/200\n",
            "boot 200/200\n",
            "Computing generalization gaps from splits...\n"
          ]
        }
      ],
      "source": [
        "print(\"Generating bootstrap train/test splits...\")\n",
        "splits = bootstrap_train_test_splits(df, groups, MODELS, train_frac=0.8, n_boot=N_BOOT, seed=42, group_col=\"group\")\n",
        "print(\"Computing generalization gaps from splits...\")\n",
        "gap_df, _, _, _ = compute_generalization(splits, groups, MODELS, rhos, alpha=1.0, group_col=\"group\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "fc44e342",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_generalization(gap_df, groups, metric=\"wr\", split=\"gap\", group_by=\"group\", out_pdf=None):\n",
        "    if out_pdf is None:\n",
        "        out_pdf = f\"{metric}_{split}_by_{group_by}.pdf\"\n",
        "    sns.set_style(\"white\")\n",
        "    plt.rcParams.update({\"font.size\":13,\"axes.labelsize\":14,\"xtick.labelsize\":12,\"ytick.labelsize\":13,\"legend.fontsize\":13,\"pdf.fonttype\":42,\"ps.fonttype\":42,\"font.family\":\"sans-serif\",\"axes.linewidth\":0.8,\"grid.linewidth\":0.4,\"xtick.major.width\":0.6,\"ytick.major.width\":0})\n",
        "    colors={\"overall\":\"#2C3E50\"}\n",
        "    default_colors=[\"#E74C3C\",\"#3498DB\",\"#F39C12\",\"#27AE60\",\"#9B59B6\",\"#1ABC9C\",\"#E67E22\"]\n",
        "    for i,grp in enumerate(groups):\n",
        "        if grp not in colors: colors[grp]=default_colors[i%len(default_colors)]\n",
        "    y_mean=f\"{metric}_{split}_mean\"\n",
        "    y_se=f\"{metric}_{split}_se\"\n",
        "    fig,ax=plt.subplots(1,1,figsize=(6,4))\n",
        "    if split==\"gap\":\n",
        "        d=gap_df[gap_df[\"group\"]==\"overall\"].sort_values(\"rho\")\n",
        "        if len(d)>0:\n",
        "            x=d[\"rho\"].to_numpy(float); y=-d[y_mean].to_numpy(float) * 100.0; se=d[y_se].to_numpy(float) * 100.0\n",
        "            ax.plot(x,y,marker=\"o\",linewidth=1.2,markersize=5,linestyle=\"-\",color=colors[\"overall\"],alpha=0.9,label=\"Overall\")\n",
        "            ax.fill_between(x,y-se,y+se,alpha=0.15,color=colors[\"overall\"])\n",
        "            ax.set_ylabel(\"Win rate generalization gap (%)\" if metric==\"wr\" else metric,fontsize=14,labelpad=4)\n",
        "        #     if np.any(np.isfinite(y)): ax.axhline(float(np.nanmin(y)),linestyle=\"--\",linewidth=1.0,color=colors[\"overall\"],alpha=0.8,label=\"min overall\")\n",
        "        # ax.legend(frameon=True,loc=\"best\",framealpha=0.95,facecolor=\"white\",edgecolor=\"lightgray\",borderpad=0.8,labelspacing=0.6)\n",
        "    else:\n",
        "        order=[\"overall\"]+list(groups)\n",
        "        for grp in order:\n",
        "            d=gap_df[gap_df[\"group\"]==grp].sort_values(\"rho\")\n",
        "            if len(d)==0: continue\n",
        "            x=d[\"rho\"].to_numpy(float); y=d[y_mean].to_numpy(float) * 100.0; se=d[y_se].to_numpy(float) * 100.0\n",
        "            ls=\"--\" if grp==\"overall\" else \"-\"\n",
        "            ax.plot(x,y,marker=\"o\",linewidth=1.2,markersize=5,linestyle=ls,color=colors.get(grp,\"#95A5A6\"),alpha=0.9,label=grp.title())\n",
        "            ax.fill_between(x,y-se,y+se,alpha=0.15,color=colors.get(grp,\"#95A5A6\"))\n",
        "            if split==\"test\":\n",
        "                ax.set_ylabel(\"Win rate on held out votes (%)\" if metric==\"wr\" else metric,fontsize=14,labelpad=4)\n",
        "            else:\n",
        "                ax.set_ylabel(\"Win rate (%)\" if metric==\"wr\" else metric,fontsize=14,labelpad=4)\n",
        "        ax.legend(frameon=True,loc=\"best\",framealpha=0.95,facecolor=\"white\",edgecolor=\"lightgray\",borderpad=0.8,labelspacing=0.6, fontsize=10)\n",
        "    ax.set_xlabel(r\"$\\rho$\",fontsize=15,labelpad=4)\n",
        "    ax.set_axisbelow(True)\n",
        "    ax.grid(True,alpha=0.25,linestyle=\"-\",linewidth=0.5,color=\"gray\")\n",
        "    ax.grid(True,axis=\"y\",alpha=0.15,linestyle=\"-\",linewidth=0.3,color=\"gray\")\n",
        "    ax.spines[\"left\"].set_linewidth(0.8); ax.spines[\"bottom\"].set_linewidth(0.8); ax.spines[\"top\"].set_visible(False); ax.spines[\"right\"].set_visible(False)\n",
        "    fig.tight_layout(pad=1.0)\n",
        "    fig.savefig(out_pdf,bbox_inches=\"tight\",dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(f\"saved: {out_pdf}\")\n",
        "\n",
        "def print_generalization_table(gap_df, groups, rhos, metric=\"wr\", split=\"gap\"):\n",
        "    df=gap_df.copy()\n",
        "    mean_col=f\"{metric}_{split}_mean\"; se_col=f\"{metric}_{split}_se\"\n",
        "    df[\"formatted\"]=df.apply(lambda row: f\"{row[mean_col]:.4f} ± {row[se_col]:.4f}\",axis=1)\n",
        "    table=df.pivot(index=\"group\",columns=\"rho\",values=\"formatted\")\n",
        "    table=table.reindex(groups+[\"overall\"])\n",
        "    display(table)\n",
        "    return table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "49b1605c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rho</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>group</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Factual Lookup</th>\n",
              "      <td>0.4085 ± 0.0183</td>\n",
              "      <td>0.4266 ± 0.0099</td>\n",
              "      <td>0.4303 ± 0.0085</td>\n",
              "      <td>0.4398 ± 0.0083</td>\n",
              "      <td>0.4442 ± 0.0072</td>\n",
              "      <td>0.4462 ± 0.0071</td>\n",
              "      <td>0.4450 ± 0.0060</td>\n",
              "      <td>0.4413 ± 0.0050</td>\n",
              "      <td>0.4384 ± 0.0052</td>\n",
              "      <td>0.4381 ± 0.0052</td>\n",
              "      <td>0.4381 ± 0.0052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Info Synthesis</th>\n",
              "      <td>0.4268 ± 0.0149</td>\n",
              "      <td>0.4444 ± 0.0106</td>\n",
              "      <td>0.4508 ± 0.0076</td>\n",
              "      <td>0.4476 ± 0.0054</td>\n",
              "      <td>0.4469 ± 0.0040</td>\n",
              "      <td>0.4483 ± 0.0047</td>\n",
              "      <td>0.4459 ± 0.0058</td>\n",
              "      <td>0.4417 ± 0.0055</td>\n",
              "      <td>0.4368 ± 0.0049</td>\n",
              "      <td>0.4364 ± 0.0049</td>\n",
              "      <td>0.4364 ± 0.0049</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recommendation</th>\n",
              "      <td>0.3165 ± 0.0214</td>\n",
              "      <td>0.3529 ± 0.0153</td>\n",
              "      <td>0.3615 ± 0.0139</td>\n",
              "      <td>0.3821 ± 0.0125</td>\n",
              "      <td>0.3992 ± 0.0097</td>\n",
              "      <td>0.4153 ± 0.0074</td>\n",
              "      <td>0.4217 ± 0.0060</td>\n",
              "      <td>0.4277 ± 0.0051</td>\n",
              "      <td>0.4334 ± 0.0044</td>\n",
              "      <td>0.4340 ± 0.0043</td>\n",
              "      <td>0.4340 ± 0.0043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Analysis</th>\n",
              "      <td>0.4120 ± 0.0176</td>\n",
              "      <td>0.4174 ± 0.0121</td>\n",
              "      <td>0.4291 ± 0.0080</td>\n",
              "      <td>0.4367 ± 0.0044</td>\n",
              "      <td>0.4345 ± 0.0045</td>\n",
              "      <td>0.4374 ± 0.0040</td>\n",
              "      <td>0.4396 ± 0.0043</td>\n",
              "      <td>0.4356 ± 0.0039</td>\n",
              "      <td>0.4348 ± 0.0043</td>\n",
              "      <td>0.4348 ± 0.0044</td>\n",
              "      <td>0.4348 ± 0.0044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>overall</th>\n",
              "      <td>0.5000 ± 0.0000</td>\n",
              "      <td>0.4950 ± 0.0011</td>\n",
              "      <td>0.4864 ± 0.0026</td>\n",
              "      <td>0.4791 ± 0.0036</td>\n",
              "      <td>0.4759 ± 0.0045</td>\n",
              "      <td>0.4737 ± 0.0039</td>\n",
              "      <td>0.4713 ± 0.0034</td>\n",
              "      <td>0.4666 ± 0.0035</td>\n",
              "      <td>0.4635 ± 0.0040</td>\n",
              "      <td>0.4638 ± 0.0041</td>\n",
              "      <td>0.4638 ± 0.0041</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "rho                         0.0              0.1              0.2  \\\n",
              "group                                                               \n",
              "Factual Lookup  0.4085 ± 0.0183  0.4266 ± 0.0099  0.4303 ± 0.0085   \n",
              "Info Synthesis  0.4268 ± 0.0149  0.4444 ± 0.0106  0.4508 ± 0.0076   \n",
              "Recommendation  0.3165 ± 0.0214  0.3529 ± 0.0153  0.3615 ± 0.0139   \n",
              "Analysis        0.4120 ± 0.0176  0.4174 ± 0.0121  0.4291 ± 0.0080   \n",
              "overall         0.5000 ± 0.0000  0.4950 ± 0.0011  0.4864 ± 0.0026   \n",
              "\n",
              "rho                         0.3              0.4              0.5  \\\n",
              "group                                                               \n",
              "Factual Lookup  0.4398 ± 0.0083  0.4442 ± 0.0072  0.4462 ± 0.0071   \n",
              "Info Synthesis  0.4476 ± 0.0054  0.4469 ± 0.0040  0.4483 ± 0.0047   \n",
              "Recommendation  0.3821 ± 0.0125  0.3992 ± 0.0097  0.4153 ± 0.0074   \n",
              "Analysis        0.4367 ± 0.0044  0.4345 ± 0.0045  0.4374 ± 0.0040   \n",
              "overall         0.4791 ± 0.0036  0.4759 ± 0.0045  0.4737 ± 0.0039   \n",
              "\n",
              "rho                         0.6              0.7              0.8  \\\n",
              "group                                                               \n",
              "Factual Lookup  0.4450 ± 0.0060  0.4413 ± 0.0050  0.4384 ± 0.0052   \n",
              "Info Synthesis  0.4459 ± 0.0058  0.4417 ± 0.0055  0.4368 ± 0.0049   \n",
              "Recommendation  0.4217 ± 0.0060  0.4277 ± 0.0051  0.4334 ± 0.0044   \n",
              "Analysis        0.4396 ± 0.0043  0.4356 ± 0.0039  0.4348 ± 0.0043   \n",
              "overall         0.4713 ± 0.0034  0.4666 ± 0.0035  0.4635 ± 0.0040   \n",
              "\n",
              "rho                         0.9              1.0  \n",
              "group                                             \n",
              "Factual Lookup  0.4381 ± 0.0052  0.4381 ± 0.0052  \n",
              "Info Synthesis  0.4364 ± 0.0049  0.4364 ± 0.0049  \n",
              "Recommendation  0.4340 ± 0.0043  0.4340 ± 0.0043  \n",
              "Analysis        0.4348 ± 0.0044  0.4348 ± 0.0044  \n",
              "overall         0.4638 ± 0.0041  0.4638 ± 0.0041  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rho</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>group</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Factual Lookup</th>\n",
              "      <td>0.3753 ± 0.0128</td>\n",
              "      <td>0.4029 ± 0.0133</td>\n",
              "      <td>0.4050 ± 0.0118</td>\n",
              "      <td>0.4167 ± 0.0110</td>\n",
              "      <td>0.4176 ± 0.0106</td>\n",
              "      <td>0.4183 ± 0.0102</td>\n",
              "      <td>0.4166 ± 0.0100</td>\n",
              "      <td>0.4145 ± 0.0096</td>\n",
              "      <td>0.4010 ± 0.0161</td>\n",
              "      <td>0.4005 ± 0.0161</td>\n",
              "      <td>0.4005 ± 0.0161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Info Synthesis</th>\n",
              "      <td>0.3852 ± 0.0126</td>\n",
              "      <td>0.3970 ± 0.0106</td>\n",
              "      <td>0.4020 ± 0.0107</td>\n",
              "      <td>0.4156 ± 0.0137</td>\n",
              "      <td>0.4151 ± 0.0146</td>\n",
              "      <td>0.4151 ± 0.0113</td>\n",
              "      <td>0.4142 ± 0.0105</td>\n",
              "      <td>0.4139 ± 0.0086</td>\n",
              "      <td>0.4196 ± 0.0093</td>\n",
              "      <td>0.4185 ± 0.0098</td>\n",
              "      <td>0.4185 ± 0.0098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recommendation</th>\n",
              "      <td>0.2791 ± 0.0192</td>\n",
              "      <td>0.2995 ± 0.0178</td>\n",
              "      <td>0.3175 ± 0.0189</td>\n",
              "      <td>0.3309 ± 0.0186</td>\n",
              "      <td>0.3400 ± 0.0154</td>\n",
              "      <td>0.3541 ± 0.0145</td>\n",
              "      <td>0.3608 ± 0.0144</td>\n",
              "      <td>0.3648 ± 0.0136</td>\n",
              "      <td>0.3670 ± 0.0129</td>\n",
              "      <td>0.3661 ± 0.0127</td>\n",
              "      <td>0.3661 ± 0.0127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Analysis</th>\n",
              "      <td>0.3550 ± 0.0244</td>\n",
              "      <td>0.3848 ± 0.0192</td>\n",
              "      <td>0.3965 ± 0.0159</td>\n",
              "      <td>0.4013 ± 0.0163</td>\n",
              "      <td>0.3968 ± 0.0163</td>\n",
              "      <td>0.3859 ± 0.0150</td>\n",
              "      <td>0.3873 ± 0.0140</td>\n",
              "      <td>0.3897 ± 0.0144</td>\n",
              "      <td>0.3963 ± 0.0148</td>\n",
              "      <td>0.3960 ± 0.0149</td>\n",
              "      <td>0.3960 ± 0.0149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>overall</th>\n",
              "      <td>0.4570 ± 0.0075</td>\n",
              "      <td>0.4629 ± 0.0071</td>\n",
              "      <td>0.4602 ± 0.0075</td>\n",
              "      <td>0.4662 ± 0.0044</td>\n",
              "      <td>0.4673 ± 0.0039</td>\n",
              "      <td>0.4673 ± 0.0029</td>\n",
              "      <td>0.4661 ± 0.0023</td>\n",
              "      <td>0.4630 ± 0.0032</td>\n",
              "      <td>0.4603 ± 0.0038</td>\n",
              "      <td>0.4598 ± 0.0040</td>\n",
              "      <td>0.4598 ± 0.0040</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "rho                         0.0              0.1              0.2  \\\n",
              "group                                                               \n",
              "Factual Lookup  0.3753 ± 0.0128  0.4029 ± 0.0133  0.4050 ± 0.0118   \n",
              "Info Synthesis  0.3852 ± 0.0126  0.3970 ± 0.0106  0.4020 ± 0.0107   \n",
              "Recommendation  0.2791 ± 0.0192  0.2995 ± 0.0178  0.3175 ± 0.0189   \n",
              "Analysis        0.3550 ± 0.0244  0.3848 ± 0.0192  0.3965 ± 0.0159   \n",
              "overall         0.4570 ± 0.0075  0.4629 ± 0.0071  0.4602 ± 0.0075   \n",
              "\n",
              "rho                         0.3              0.4              0.5  \\\n",
              "group                                                               \n",
              "Factual Lookup  0.4167 ± 0.0110  0.4176 ± 0.0106  0.4183 ± 0.0102   \n",
              "Info Synthesis  0.4156 ± 0.0137  0.4151 ± 0.0146  0.4151 ± 0.0113   \n",
              "Recommendation  0.3309 ± 0.0186  0.3400 ± 0.0154  0.3541 ± 0.0145   \n",
              "Analysis        0.4013 ± 0.0163  0.3968 ± 0.0163  0.3859 ± 0.0150   \n",
              "overall         0.4662 ± 0.0044  0.4673 ± 0.0039  0.4673 ± 0.0029   \n",
              "\n",
              "rho                         0.6              0.7              0.8  \\\n",
              "group                                                               \n",
              "Factual Lookup  0.4166 ± 0.0100  0.4145 ± 0.0096  0.4010 ± 0.0161   \n",
              "Info Synthesis  0.4142 ± 0.0105  0.4139 ± 0.0086  0.4196 ± 0.0093   \n",
              "Recommendation  0.3608 ± 0.0144  0.3648 ± 0.0136  0.3670 ± 0.0129   \n",
              "Analysis        0.3873 ± 0.0140  0.3897 ± 0.0144  0.3963 ± 0.0148   \n",
              "overall         0.4661 ± 0.0023  0.4630 ± 0.0032  0.4603 ± 0.0038   \n",
              "\n",
              "rho                         0.9              1.0  \n",
              "group                                             \n",
              "Factual Lookup  0.4005 ± 0.0161  0.4005 ± 0.0161  \n",
              "Info Synthesis  0.4185 ± 0.0098  0.4185 ± 0.0098  \n",
              "Recommendation  0.3661 ± 0.0127  0.3661 ± 0.0127  \n",
              "Analysis        0.3960 ± 0.0149  0.3960 ± 0.0149  \n",
              "overall         0.4598 ± 0.0040  0.4598 ± 0.0040  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rho</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>group</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Factual Lookup</th>\n",
              "      <td>-0.0332 ± 0.0248</td>\n",
              "      <td>-0.0237 ± 0.0183</td>\n",
              "      <td>-0.0253 ± 0.0113</td>\n",
              "      <td>-0.0230 ± 0.0129</td>\n",
              "      <td>-0.0266 ± 0.0144</td>\n",
              "      <td>-0.0278 ± 0.0145</td>\n",
              "      <td>-0.0284 ± 0.0133</td>\n",
              "      <td>-0.0268 ± 0.0122</td>\n",
              "      <td>-0.0375 ± 0.0176</td>\n",
              "      <td>-0.0376 ± 0.0177</td>\n",
              "      <td>-0.0376 ± 0.0177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Info Synthesis</th>\n",
              "      <td>-0.0416 ± 0.0161</td>\n",
              "      <td>-0.0474 ± 0.0130</td>\n",
              "      <td>-0.0488 ± 0.0130</td>\n",
              "      <td>-0.0320 ± 0.0154</td>\n",
              "      <td>-0.0318 ± 0.0167</td>\n",
              "      <td>-0.0333 ± 0.0144</td>\n",
              "      <td>-0.0317 ± 0.0141</td>\n",
              "      <td>-0.0278 ± 0.0127</td>\n",
              "      <td>-0.0172 ± 0.0118</td>\n",
              "      <td>-0.0179 ± 0.0122</td>\n",
              "      <td>-0.0179 ± 0.0122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recommendation</th>\n",
              "      <td>-0.0374 ± 0.0211</td>\n",
              "      <td>-0.0534 ± 0.0135</td>\n",
              "      <td>-0.0440 ± 0.0170</td>\n",
              "      <td>-0.0512 ± 0.0183</td>\n",
              "      <td>-0.0593 ± 0.0172</td>\n",
              "      <td>-0.0612 ± 0.0151</td>\n",
              "      <td>-0.0609 ± 0.0143</td>\n",
              "      <td>-0.0629 ± 0.0140</td>\n",
              "      <td>-0.0664 ± 0.0134</td>\n",
              "      <td>-0.0678 ± 0.0132</td>\n",
              "      <td>-0.0678 ± 0.0132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Analysis</th>\n",
              "      <td>-0.0571 ± 0.0199</td>\n",
              "      <td>-0.0326 ± 0.0199</td>\n",
              "      <td>-0.0326 ± 0.0159</td>\n",
              "      <td>-0.0354 ± 0.0166</td>\n",
              "      <td>-0.0377 ± 0.0169</td>\n",
              "      <td>-0.0515 ± 0.0163</td>\n",
              "      <td>-0.0523 ± 0.0153</td>\n",
              "      <td>-0.0459 ± 0.0140</td>\n",
              "      <td>-0.0386 ± 0.0135</td>\n",
              "      <td>-0.0388 ± 0.0136</td>\n",
              "      <td>-0.0388 ± 0.0136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>overall</th>\n",
              "      <td>-0.0430 ± 0.0075</td>\n",
              "      <td>-0.0321 ± 0.0066</td>\n",
              "      <td>-0.0262 ± 0.0069</td>\n",
              "      <td>-0.0130 ± 0.0040</td>\n",
              "      <td>-0.0085 ± 0.0045</td>\n",
              "      <td>-0.0064 ± 0.0047</td>\n",
              "      <td>-0.0052 ± 0.0049</td>\n",
              "      <td>-0.0037 ± 0.0048</td>\n",
              "      <td>-0.0032 ± 0.0049</td>\n",
              "      <td>-0.0040 ± 0.0052</td>\n",
              "      <td>-0.0040 ± 0.0052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "rho                          0.0               0.1               0.2  \\\n",
              "group                                                                  \n",
              "Factual Lookup  -0.0332 ± 0.0248  -0.0237 ± 0.0183  -0.0253 ± 0.0113   \n",
              "Info Synthesis  -0.0416 ± 0.0161  -0.0474 ± 0.0130  -0.0488 ± 0.0130   \n",
              "Recommendation  -0.0374 ± 0.0211  -0.0534 ± 0.0135  -0.0440 ± 0.0170   \n",
              "Analysis        -0.0571 ± 0.0199  -0.0326 ± 0.0199  -0.0326 ± 0.0159   \n",
              "overall         -0.0430 ± 0.0075  -0.0321 ± 0.0066  -0.0262 ± 0.0069   \n",
              "\n",
              "rho                          0.3               0.4               0.5  \\\n",
              "group                                                                  \n",
              "Factual Lookup  -0.0230 ± 0.0129  -0.0266 ± 0.0144  -0.0278 ± 0.0145   \n",
              "Info Synthesis  -0.0320 ± 0.0154  -0.0318 ± 0.0167  -0.0333 ± 0.0144   \n",
              "Recommendation  -0.0512 ± 0.0183  -0.0593 ± 0.0172  -0.0612 ± 0.0151   \n",
              "Analysis        -0.0354 ± 0.0166  -0.0377 ± 0.0169  -0.0515 ± 0.0163   \n",
              "overall         -0.0130 ± 0.0040  -0.0085 ± 0.0045  -0.0064 ± 0.0047   \n",
              "\n",
              "rho                          0.6               0.7               0.8  \\\n",
              "group                                                                  \n",
              "Factual Lookup  -0.0284 ± 0.0133  -0.0268 ± 0.0122  -0.0375 ± 0.0176   \n",
              "Info Synthesis  -0.0317 ± 0.0141  -0.0278 ± 0.0127  -0.0172 ± 0.0118   \n",
              "Recommendation  -0.0609 ± 0.0143  -0.0629 ± 0.0140  -0.0664 ± 0.0134   \n",
              "Analysis        -0.0523 ± 0.0153  -0.0459 ± 0.0140  -0.0386 ± 0.0135   \n",
              "overall         -0.0052 ± 0.0049  -0.0037 ± 0.0048  -0.0032 ± 0.0049   \n",
              "\n",
              "rho                          0.9               1.0  \n",
              "group                                               \n",
              "Factual Lookup  -0.0376 ± 0.0177  -0.0376 ± 0.0177  \n",
              "Info Synthesis  -0.0179 ± 0.0122  -0.0179 ± 0.0122  \n",
              "Recommendation  -0.0678 ± 0.0132  -0.0678 ± 0.0132  \n",
              "Analysis        -0.0388 ± 0.0136  -0.0388 ± 0.0136  \n",
              "overall         -0.0040 ± 0.0052  -0.0040 ± 0.0052  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rho</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>group</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Factual Lookup</th>\n",
              "      <td>-0.0332 ± 0.0248</td>\n",
              "      <td>-0.0237 ± 0.0183</td>\n",
              "      <td>-0.0253 ± 0.0113</td>\n",
              "      <td>-0.0230 ± 0.0129</td>\n",
              "      <td>-0.0266 ± 0.0144</td>\n",
              "      <td>-0.0278 ± 0.0145</td>\n",
              "      <td>-0.0284 ± 0.0133</td>\n",
              "      <td>-0.0268 ± 0.0122</td>\n",
              "      <td>-0.0375 ± 0.0176</td>\n",
              "      <td>-0.0376 ± 0.0177</td>\n",
              "      <td>-0.0376 ± 0.0177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Info Synthesis</th>\n",
              "      <td>-0.0416 ± 0.0161</td>\n",
              "      <td>-0.0474 ± 0.0130</td>\n",
              "      <td>-0.0488 ± 0.0130</td>\n",
              "      <td>-0.0320 ± 0.0154</td>\n",
              "      <td>-0.0318 ± 0.0167</td>\n",
              "      <td>-0.0333 ± 0.0144</td>\n",
              "      <td>-0.0317 ± 0.0141</td>\n",
              "      <td>-0.0278 ± 0.0127</td>\n",
              "      <td>-0.0172 ± 0.0118</td>\n",
              "      <td>-0.0179 ± 0.0122</td>\n",
              "      <td>-0.0179 ± 0.0122</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Recommendation</th>\n",
              "      <td>-0.0374 ± 0.0211</td>\n",
              "      <td>-0.0534 ± 0.0135</td>\n",
              "      <td>-0.0440 ± 0.0170</td>\n",
              "      <td>-0.0512 ± 0.0183</td>\n",
              "      <td>-0.0593 ± 0.0172</td>\n",
              "      <td>-0.0612 ± 0.0151</td>\n",
              "      <td>-0.0609 ± 0.0143</td>\n",
              "      <td>-0.0629 ± 0.0140</td>\n",
              "      <td>-0.0664 ± 0.0134</td>\n",
              "      <td>-0.0678 ± 0.0132</td>\n",
              "      <td>-0.0678 ± 0.0132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Analysis</th>\n",
              "      <td>-0.0571 ± 0.0199</td>\n",
              "      <td>-0.0326 ± 0.0199</td>\n",
              "      <td>-0.0326 ± 0.0159</td>\n",
              "      <td>-0.0354 ± 0.0166</td>\n",
              "      <td>-0.0377 ± 0.0169</td>\n",
              "      <td>-0.0515 ± 0.0163</td>\n",
              "      <td>-0.0523 ± 0.0153</td>\n",
              "      <td>-0.0459 ± 0.0140</td>\n",
              "      <td>-0.0386 ± 0.0135</td>\n",
              "      <td>-0.0388 ± 0.0136</td>\n",
              "      <td>-0.0388 ± 0.0136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>overall</th>\n",
              "      <td>-0.0430 ± 0.0075</td>\n",
              "      <td>-0.0321 ± 0.0066</td>\n",
              "      <td>-0.0262 ± 0.0069</td>\n",
              "      <td>-0.0130 ± 0.0040</td>\n",
              "      <td>-0.0085 ± 0.0045</td>\n",
              "      <td>-0.0064 ± 0.0047</td>\n",
              "      <td>-0.0052 ± 0.0049</td>\n",
              "      <td>-0.0037 ± 0.0048</td>\n",
              "      <td>-0.0032 ± 0.0049</td>\n",
              "      <td>-0.0040 ± 0.0052</td>\n",
              "      <td>-0.0040 ± 0.0052</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "rho                          0.0               0.1               0.2  \\\n",
              "group                                                                  \n",
              "Factual Lookup  -0.0332 ± 0.0248  -0.0237 ± 0.0183  -0.0253 ± 0.0113   \n",
              "Info Synthesis  -0.0416 ± 0.0161  -0.0474 ± 0.0130  -0.0488 ± 0.0130   \n",
              "Recommendation  -0.0374 ± 0.0211  -0.0534 ± 0.0135  -0.0440 ± 0.0170   \n",
              "Analysis        -0.0571 ± 0.0199  -0.0326 ± 0.0199  -0.0326 ± 0.0159   \n",
              "overall         -0.0430 ± 0.0075  -0.0321 ± 0.0066  -0.0262 ± 0.0069   \n",
              "\n",
              "rho                          0.3               0.4               0.5  \\\n",
              "group                                                                  \n",
              "Factual Lookup  -0.0230 ± 0.0129  -0.0266 ± 0.0144  -0.0278 ± 0.0145   \n",
              "Info Synthesis  -0.0320 ± 0.0154  -0.0318 ± 0.0167  -0.0333 ± 0.0144   \n",
              "Recommendation  -0.0512 ± 0.0183  -0.0593 ± 0.0172  -0.0612 ± 0.0151   \n",
              "Analysis        -0.0354 ± 0.0166  -0.0377 ± 0.0169  -0.0515 ± 0.0163   \n",
              "overall         -0.0130 ± 0.0040  -0.0085 ± 0.0045  -0.0064 ± 0.0047   \n",
              "\n",
              "rho                          0.6               0.7               0.8  \\\n",
              "group                                                                  \n",
              "Factual Lookup  -0.0284 ± 0.0133  -0.0268 ± 0.0122  -0.0375 ± 0.0176   \n",
              "Info Synthesis  -0.0317 ± 0.0141  -0.0278 ± 0.0127  -0.0172 ± 0.0118   \n",
              "Recommendation  -0.0609 ± 0.0143  -0.0629 ± 0.0140  -0.0664 ± 0.0134   \n",
              "Analysis        -0.0523 ± 0.0153  -0.0459 ± 0.0140  -0.0386 ± 0.0135   \n",
              "overall         -0.0052 ± 0.0049  -0.0037 ± 0.0048  -0.0032 ± 0.0049   \n",
              "\n",
              "rho                          0.9               1.0  \n",
              "group                                               \n",
              "Factual Lookup  -0.0376 ± 0.0177  -0.0376 ± 0.0177  \n",
              "Info Synthesis  -0.0179 ± 0.0122  -0.0179 ± 0.0122  \n",
              "Recommendation  -0.0678 ± 0.0132  -0.0678 ± 0.0132  \n",
              "Analysis        -0.0388 ± 0.0136  -0.0388 ± 0.0136  \n",
              "overall         -0.0040 ± 0.0052  -0.0040 ± 0.0052  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print_generalization_table(gap_df, groups, rhos, metric=\"wr\", split=\"train\")\n",
        "print_generalization_table(gap_df, groups, rhos, metric=\"wr\", split=\"test\")\n",
        "print_generalization_table(gap_df, groups, rhos, metric=\"wr\", split=\"gap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d1c7d2eb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: wr_train_by_primary_intent.pdf\n",
            "saved: wr_test_by_primary_intent.pdf\n",
            "saved: wr_gap_by_primary_intent.pdf\n"
          ]
        }
      ],
      "source": [
        "plot_generalization(gap_df, groups, metric=\"wr\", split=\"train\", group_by=GROUP_BY, out_pdf=f\"wr_train_by_{GROUP_BY}.pdf\")\n",
        "plot_generalization(gap_df, groups, metric=\"wr\", split=\"test\", group_by=GROUP_BY, out_pdf=f\"wr_test_by_{GROUP_BY}.pdf\")\n",
        "plot_generalization(gap_df, groups, metric=\"wr\", split=\"gap\", group_by=GROUP_BY, out_pdf=f\"wr_gap_by_{GROUP_BY}.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "76d21a02",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(shown if mean> 2.0% for some rho)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>rho</th>\n",
              "      <th>0.0</th>\n",
              "      <th>0.1</th>\n",
              "      <th>0.2</th>\n",
              "      <th>0.3</th>\n",
              "      <th>0.4</th>\n",
              "      <th>0.5</th>\n",
              "      <th>0.6</th>\n",
              "      <th>0.7</th>\n",
              "      <th>0.8</th>\n",
              "      <th>0.9</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>sonar-reasoning-pro-high</th>\n",
              "      <td>48.74 ± 2.92</td>\n",
              "      <td>45.74 ± 2.18</td>\n",
              "      <td>42.04 ± 1.61</td>\n",
              "      <td>35.89 ± 1.35</td>\n",
              "      <td>33.07 ± 1.20</td>\n",
              "      <td>31.70 ± 1.14</td>\n",
              "      <td>31.09 ± 1.09</td>\n",
              "      <td>31.92 ± 1.08</td>\n",
              "      <td>32.15 ± 1.08</td>\n",
              "      <td>32.30 ± 1.07</td>\n",
              "      <td>32.30 ± 1.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gemini-2.5-pro-exp-03-25-grounding</th>\n",
              "      <td>34.15 ± 2.67</td>\n",
              "      <td>34.72 ± 2.13</td>\n",
              "      <td>32.52 ± 1.78</td>\n",
              "      <td>31.71 ± 1.60</td>\n",
              "      <td>30.82 ± 1.48</td>\n",
              "      <td>29.01 ± 1.36</td>\n",
              "      <td>28.11 ± 1.27</td>\n",
              "      <td>26.58 ± 1.21</td>\n",
              "      <td>25.75 ± 1.21</td>\n",
              "      <td>25.57 ± 1.21</td>\n",
              "      <td>25.57 ± 1.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sonar-pro-high</th>\n",
              "      <td>9.23 ± 1.51</td>\n",
              "      <td>11.53 ± 1.20</td>\n",
              "      <td>14.67 ± 0.99</td>\n",
              "      <td>17.26 ± 0.88</td>\n",
              "      <td>18.47 ± 0.83</td>\n",
              "      <td>19.11 ± 0.82</td>\n",
              "      <td>19.56 ± 0.82</td>\n",
              "      <td>19.65 ± 0.81</td>\n",
              "      <td>20.08 ± 0.81</td>\n",
              "      <td>20.20 ± 0.82</td>\n",
              "      <td>20.20 ± 0.82</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sonar</th>\n",
              "      <td>5.27 ± 0.94</td>\n",
              "      <td>5.86 ± 0.84</td>\n",
              "      <td>7.43 ± 0.83</td>\n",
              "      <td>9.10 ± 0.84</td>\n",
              "      <td>10.02 ± 0.80</td>\n",
              "      <td>10.98 ± 0.80</td>\n",
              "      <td>10.98 ± 0.78</td>\n",
              "      <td>10.62 ± 0.76</td>\n",
              "      <td>9.90 ± 0.76</td>\n",
              "      <td>9.75 ± 0.75</td>\n",
              "      <td>9.75 ± 0.75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sonar-reasoning</th>\n",
              "      <td>1.86 ± 0.40</td>\n",
              "      <td>1.56 ± 0.28</td>\n",
              "      <td>2.07 ± 0.35</td>\n",
              "      <td>3.43 ± 0.47</td>\n",
              "      <td>3.37 ± 0.47</td>\n",
              "      <td>3.10 ± 0.42</td>\n",
              "      <td>2.62 ± 0.38</td>\n",
              "      <td>2.50 ± 0.38</td>\n",
              "      <td>2.54 ± 0.38</td>\n",
              "      <td>2.53 ± 0.37</td>\n",
              "      <td>2.53 ± 0.37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sonar-pro</th>\n",
              "      <td>0.38 ± 0.18</td>\n",
              "      <td>0.47 ± 0.16</td>\n",
              "      <td>0.92 ± 0.24</td>\n",
              "      <td>1.39 ± 0.30</td>\n",
              "      <td>1.97 ± 0.34</td>\n",
              "      <td>2.50 ± 0.36</td>\n",
              "      <td>2.73 ± 0.38</td>\n",
              "      <td>2.72 ± 0.37</td>\n",
              "      <td>2.79 ± 0.40</td>\n",
              "      <td>2.76 ± 0.40</td>\n",
              "      <td>2.76 ± 0.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gemini-2.5-pro-exp-03-25-wo-search</th>\n",
              "      <td>0.23 ± 0.12</td>\n",
              "      <td>0.06 ± 0.05</td>\n",
              "      <td>0.22 ± 0.10</td>\n",
              "      <td>0.88 ± 0.21</td>\n",
              "      <td>1.57 ± 0.29</td>\n",
              "      <td>2.39 ± 0.36</td>\n",
              "      <td>3.22 ± 0.41</td>\n",
              "      <td>3.81 ± 0.43</td>\n",
              "      <td>4.37 ± 0.48</td>\n",
              "      <td>4.41 ± 0.48</td>\n",
              "      <td>4.41 ± 0.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gemini-2.5-flash-preview-04-17-grounding</th>\n",
              "      <td>0.14 ± 0.14</td>\n",
              "      <td>0.06 ± 0.06</td>\n",
              "      <td>0.13 ± 0.08</td>\n",
              "      <td>0.34 ± 0.11</td>\n",
              "      <td>0.72 ± 0.18</td>\n",
              "      <td>1.19 ± 0.26</td>\n",
              "      <td>1.63 ± 0.30</td>\n",
              "      <td>2.09 ± 0.34</td>\n",
              "      <td>2.26 ± 0.35</td>\n",
              "      <td>2.31 ± 0.35</td>\n",
              "      <td>2.31 ± 0.35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "rho                                                0.0           0.1  \\\n",
              "model                                                                  \n",
              "sonar-reasoning-pro-high                  48.74 ± 2.92  45.74 ± 2.18   \n",
              "gemini-2.5-pro-exp-03-25-grounding        34.15 ± 2.67  34.72 ± 2.13   \n",
              "sonar-pro-high                             9.23 ± 1.51  11.53 ± 1.20   \n",
              "sonar                                      5.27 ± 0.94   5.86 ± 0.84   \n",
              "sonar-reasoning                            1.86 ± 0.40   1.56 ± 0.28   \n",
              "sonar-pro                                  0.38 ± 0.18   0.47 ± 0.16   \n",
              "gemini-2.5-pro-exp-03-25-wo-search         0.23 ± 0.12   0.06 ± 0.05   \n",
              "gemini-2.5-flash-preview-04-17-grounding   0.14 ± 0.14   0.06 ± 0.06   \n",
              "\n",
              "rho                                                0.2           0.3  \\\n",
              "model                                                                  \n",
              "sonar-reasoning-pro-high                  42.04 ± 1.61  35.89 ± 1.35   \n",
              "gemini-2.5-pro-exp-03-25-grounding        32.52 ± 1.78  31.71 ± 1.60   \n",
              "sonar-pro-high                            14.67 ± 0.99  17.26 ± 0.88   \n",
              "sonar                                      7.43 ± 0.83   9.10 ± 0.84   \n",
              "sonar-reasoning                            2.07 ± 0.35   3.43 ± 0.47   \n",
              "sonar-pro                                  0.92 ± 0.24   1.39 ± 0.30   \n",
              "gemini-2.5-pro-exp-03-25-wo-search         0.22 ± 0.10   0.88 ± 0.21   \n",
              "gemini-2.5-flash-preview-04-17-grounding   0.13 ± 0.08   0.34 ± 0.11   \n",
              "\n",
              "rho                                                0.4           0.5  \\\n",
              "model                                                                  \n",
              "sonar-reasoning-pro-high                  33.07 ± 1.20  31.70 ± 1.14   \n",
              "gemini-2.5-pro-exp-03-25-grounding        30.82 ± 1.48  29.01 ± 1.36   \n",
              "sonar-pro-high                            18.47 ± 0.83  19.11 ± 0.82   \n",
              "sonar                                     10.02 ± 0.80  10.98 ± 0.80   \n",
              "sonar-reasoning                            3.37 ± 0.47   3.10 ± 0.42   \n",
              "sonar-pro                                  1.97 ± 0.34   2.50 ± 0.36   \n",
              "gemini-2.5-pro-exp-03-25-wo-search         1.57 ± 0.29   2.39 ± 0.36   \n",
              "gemini-2.5-flash-preview-04-17-grounding   0.72 ± 0.18   1.19 ± 0.26   \n",
              "\n",
              "rho                                                0.6           0.7  \\\n",
              "model                                                                  \n",
              "sonar-reasoning-pro-high                  31.09 ± 1.09  31.92 ± 1.08   \n",
              "gemini-2.5-pro-exp-03-25-grounding        28.11 ± 1.27  26.58 ± 1.21   \n",
              "sonar-pro-high                            19.56 ± 0.82  19.65 ± 0.81   \n",
              "sonar                                     10.98 ± 0.78  10.62 ± 0.76   \n",
              "sonar-reasoning                            2.62 ± 0.38   2.50 ± 0.38   \n",
              "sonar-pro                                  2.73 ± 0.38   2.72 ± 0.37   \n",
              "gemini-2.5-pro-exp-03-25-wo-search         3.22 ± 0.41   3.81 ± 0.43   \n",
              "gemini-2.5-flash-preview-04-17-grounding   1.63 ± 0.30   2.09 ± 0.34   \n",
              "\n",
              "rho                                                0.8           0.9  \\\n",
              "model                                                                  \n",
              "sonar-reasoning-pro-high                  32.15 ± 1.08  32.30 ± 1.07   \n",
              "gemini-2.5-pro-exp-03-25-grounding        25.75 ± 1.21  25.57 ± 1.21   \n",
              "sonar-pro-high                            20.08 ± 0.81  20.20 ± 0.82   \n",
              "sonar                                      9.90 ± 0.76   9.75 ± 0.75   \n",
              "sonar-reasoning                            2.54 ± 0.38   2.53 ± 0.37   \n",
              "sonar-pro                                  2.79 ± 0.40   2.76 ± 0.40   \n",
              "gemini-2.5-pro-exp-03-25-wo-search         4.37 ± 0.48   4.41 ± 0.48   \n",
              "gemini-2.5-flash-preview-04-17-grounding   2.26 ± 0.35   2.31 ± 0.35   \n",
              "\n",
              "rho                                                1.0  \n",
              "model                                                   \n",
              "sonar-reasoning-pro-high                  32.30 ± 1.07  \n",
              "gemini-2.5-pro-exp-03-25-grounding        25.57 ± 1.21  \n",
              "sonar-pro-high                            20.20 ± 0.82  \n",
              "sonar                                      9.75 ± 0.75  \n",
              "sonar-reasoning                            2.53 ± 0.37  \n",
              "sonar-pro                                  2.76 ± 0.40  \n",
              "gemini-2.5-pro-exp-03-25-wo-search         4.41 ± 0.48  \n",
              "gemini-2.5-flash-preview-04-17-grounding   2.31 ± 0.35  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def print_boot_p(boot_p, models, rhos, thresh=0.02):\n",
        "    rows = []\n",
        "    for rho in rhos:\n",
        "        P = np.vstack(boot_p[rho])\n",
        "        mean = P.mean(axis=0)\n",
        "        se = P.std(axis=0) / np.sqrt(P.shape[0])\n",
        "        for i, name in enumerate(models):\n",
        "            rows.append({\"rho\": rho, \"model\": name, \"mean\": mean[i], \"se\": se[i]})\n",
        "    wdf = pd.DataFrame(rows)\n",
        "    keep = wdf.groupby(\"model\")[\"mean\"].max()\n",
        "    keep = keep[keep > thresh].index\n",
        "    wdf = wdf[wdf[\"model\"].isin(keep)].copy()\n",
        "    wdf[\"mean%\"] = (100*wdf[\"mean\"]).round(2)\n",
        "    wdf[\"se%\"] = (100*wdf[\"se\"]).round(2)\n",
        "    \n",
        "    wdf[\"formatted\"] = wdf.apply(lambda row: f\"{row['mean%']:.2f} ± {row['se%']:.2f}\", axis=1)\n",
        "    \n",
        "    table = wdf.pivot(index=\"model\", columns=\"rho\", values=\"formatted\")\n",
        "    \n",
        "    rho0_means = wdf[wdf[\"rho\"] == rhos[0]].set_index(\"model\")[\"mean\"].sort_values(ascending=False)\n",
        "    table = table.reindex(rho0_means.index)\n",
        "    \n",
        "    print(f\"(shown if mean> {100*thresh:.1f}% for some rho)\")\n",
        "    display(table)\n",
        "    return wdf\n",
        "\n",
        "wdf = print_boot_p(boot_p, MODELS, rhos, thresh=0.02)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "7a53c187",
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_model_performance_grid(wdf, out_pdf=None):\n",
        "    if out_pdf is None:\n",
        "        out_pdf = f\"model_performance_grid_{GROUP_BY}.pdf\"\n",
        "    sns.set_style(\"white\")\n",
        "    plt.rcParams.update({\"font.size\":10,\"axes.labelsize\":11,\"xtick.labelsize\":9,\"ytick.labelsize\":10,\"legend.fontsize\":10,\"pdf.fonttype\":42,\"ps.fonttype\":42,\"font.family\":\"sans-serif\",\"axes.linewidth\":0.8,\"grid.linewidth\":0.4,\"xtick.major.width\":0.6,\"ytick.major.width\":0})\n",
        "    rhos_to_plot=[0.0,0.4,0.7,1.0]\n",
        "    model_names={'gemini-2.0-flash-grounding':'Gemini 2.0 Flash','gemini-2.5-flash-preview-04-17-grounding':'Gemini 2.5 Flash','gemini-2.5-pro-exp-03-25-grounding':'Gemini 2.5 Pro','gemini-2.5-pro-exp-03-25-wo-search':'Gemini 2.5 Pro (no search)','gpt-4o-mini-search-preview':'GPT-4o Mini','gpt-4o-search-preview':'GPT-4o','gpt-4o-search-preview-high':'GPT-4o High','gpt-4o-search-preview-high-loc':'GPT-4o High Loc','sonar':'Sonar','sonar-pro':'Sonar Pro','sonar-pro-high':'Sonar Pro High','sonar-reasoning':'Sonar Reasoning','sonar-reasoning-pro-high':'Sonar Reasoning Pro High'}\n",
        "    colors={'sonar-reasoning-pro-high':'#E74C3C','gemini-2.5-pro-exp-03-25-grounding':'#3498DB','sonar-pro-high':'#F39C12','sonar':'#27AE60','sonar-pro':'#9B59B6','sonar-reasoning':'#1ABC9C','gemini-2.5-pro-exp-03-25-wo-search':'#E67E22','gemini-2.5-flash-preview-04-17-grounding':'#E91E63'}\n",
        "    fig,axes=plt.subplots(1,4,figsize=(18,5)); axes=axes.flatten()\n",
        "    models_ordered=wdf[np.isclose(wdf[\"rho\"],0.0)].sort_values(\"mean\",ascending=True)[\"model\"].values\n",
        "    for idx,rho in enumerate(rhos_to_plot):\n",
        "        ax=axes[idx]\n",
        "        data=wdf[np.isclose(wdf[\"rho\"],rho)].copy()\n",
        "        data=data.set_index(\"model\").reindex(models_ordered).reset_index().dropna()\n",
        "        bar_spacing=0.65\n",
        "        y_pos=np.arange(len(data))*bar_spacing\n",
        "        bar_colors=[colors.get(m,\"#95A5A6\") for m in data[\"model\"]]\n",
        "        ax.barh(y_pos,data[\"mean%\"],xerr=data[\"se%\"],color=bar_colors,error_kw={\"elinewidth\":1.2,\"capsize\":2.5,\"alpha\":0.7},height=0.5*bar_spacing,alpha=0.85,edgecolor=\"white\",linewidth=0.5)\n",
        "        ax.set_xlim(0,75); ax.set_xticks([0,20,40,60,80])\n",
        "        ax.set_axisbelow(True)\n",
        "        ax.grid(True,axis=\"x\",alpha=0.25,linestyle=\"-\",linewidth=0.5,color=\"gray\")\n",
        "        ax.grid(True,axis=\"y\",alpha=0.15,linestyle=\"-\",linewidth=0.3,color=\"gray\")\n",
        "        if idx==0:\n",
        "            ax.set_yticks(y_pos)\n",
        "            ax.set_yticklabels([model_names.get(m,m) for m in data[\"model\"]],fontsize=12)\n",
        "        else:\n",
        "            ax.set_yticks(y_pos)\n",
        "            ax.set_yticklabels([])\n",
        "        ax.set_xlabel(\"Probability (%)\",fontsize=14,labelpad=4)\n",
        "        ax.set_xticklabels([\"0\",\"20\",\"40\",\"60\",\"80\"],fontsize=14)\n",
        "        ax.text(0.95,0.1,f\"ρ = {rho:.1f}\",transform=ax.transAxes,fontsize=16,fontweight=\"bold\",ha=\"right\",va=\"bottom\",bbox=dict(boxstyle=\"round,pad=0.4\",facecolor=\"white\",edgecolor=\"lightgray\",alpha=0.8,linewidth=0.5))\n",
        "        ax.spines[\"left\"].set_linewidth(0.8); ax.spines[\"bottom\"].set_linewidth(0.8); ax.spines[\"top\"].set_visible(False); ax.spines[\"right\"].set_visible(False)\n",
        "    fig.tight_layout(pad=1.2)\n",
        "    fig.savefig(out_pdf,bbox_inches=\"tight\",dpi=300)\n",
        "    plt.close(fig)\n",
        "    print(f\"saved: {out_pdf}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "3684a0c1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "saved: model_performance_grid_primary_intent.pdf\n"
          ]
        }
      ],
      "source": [
        "plot_model_performance_grid(wdf)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "buggy",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
